import os
import streamlit as st
import requests
from langchain_openai import ChatOpenAI
from dotenv import load_dotenv
from pydantic import BaseModel
from langchain_core.messages import ChatMessage
from langchain_core.output_parsers import PydanticOutputParser
from langchain_core.prompts import PromptTemplate
from langchain_core.tools import tool
from langchain_core.runnables import RunnablePassthrough, RunnableSequence
from langchain_core.callbacks.base import BaseCallbackHandler
from langchain_openai import OpenAIEmbeddings


# Streamlit í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="AI Book Search",
    page_icon="ğŸ¤–",
)

st.title("ğŸ¤–AI Book SearchğŸ¤–")

st.markdown(
    """
    ### ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ í†µí•´ ê´€ë ¨ ë„ì„œë¥¼ ì¶”ì²œí•´ì£¼ëŠ” AIì…ë‹ˆë‹¤. 
    
    - ì‹œí—˜ì´ë‚˜ ìê²©ì¦ì„ ë§í•´ì£¼ì‹œê³ , ë³¸ì¸ì˜ í˜„ì¬ ì‹¤ë ¥ë„ ë§í•´ì£¼ì„¸ìš”(ex. ìƒ, ì¤‘, í•˜)
    - ë‹µë³€ì€ ê²€ìƒ‰ëœ ë„ì„œ ëª©ë¡ìœ¼ë¡œ ì œê³µë©ë‹ˆë‹¤.

    - ë„ì„œ ê´€ë ¨ ì£¼ì œ íŒë‹¨ ê¸°ì¤€:
        1. ì§ˆë¬¸ì— ë„ì„œ ì œëª©, ì €ì, ì¶œíŒì‚¬, ì¶œíŒ ì—°ë„, ì¥ë¥´ ë“±ì˜ í‚¤ì›Œë“œê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.
        2. ì§ˆë¬¸ì˜ ì˜ë„ê°€ ë„ì„œ ì •ë³´ë¥¼ ìš”êµ¬í•˜ê±°ë‚˜ ì±… ì¶”ì²œì„ ìš”ì²­í•˜ëŠ”ì§€ ë¶„ì„í•˜ì„¸ìš”.
        3. ë„ì„œ ì„ íƒ, ì„¸ë¶€ ì •ë³´, ë¦¬ë·°, í™œìš©ê³¼ ê´€ë ¨ëœ ì¼ë°˜ì ì¸ ì£¼ì œì¸ì§€ íŒë‹¨í•˜ì„¸ìš”.
        4. ì§ˆì˜ ìœ í˜•ì´ ì •ë³´ ê²€ìƒ‰í˜•ì¸ì§€, ë„ì„œ ì¶”ì²œ ì˜ë„ê°€ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.
        5. ë„ì„œì™€ ê´€ë ¨ ì—†ëŠ” ì§ˆë¬¸(ì˜ˆ: \"ì±…ìƒ ì¶”ì²œ\")ì€ ì œì™¸í•˜ì„¸ìš”.
    """
)


# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ 
load_dotenv()

# ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™” 
embedding_model = OpenAIEmbeddings(
    model=os.getenv("OPENAI_EMBEDDING_MODEL")
)

# í™˜ê²½ ë³€ìˆ˜ì—ì„œ OpenAI API í‚¤ë¥¼ ë¶ˆëŸ¬ì˜¤ê¸°
openai_api_key = os.getenv("OPENAI_API_KEY")
if not openai_api_key:
    print("OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")

# ë„¤ì´ë²„ clinet ê°’ ë¶ˆëŸ¬ì˜¤ê¸°
NAVER_CLIENT_ID = os.getenv("NAVER_CLIENT_ID")
if not NAVER_CLIENT_ID:
    print("NAVER_CLIENT_ID í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")

NAVER_CLIENT_SECRET = os.getenv("NAVER_CLIENT_SECRET")
if not NAVER_CLIENT_SECRET:
    print("NAVER_CLIENT_SECRET í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")

NAVER_BOOKS_URL = "https://openapi.naver.com/v1/search/book.json?"


# ë„ì„œ ê²€ìƒ‰ 
def search_books(query: str, k: int = 10):
    """
    ë„¤ì´ë²„ ë„ì„œ ê²€ìƒ‰ APIë¥¼ ì‚¬ìš©í•˜ì—¬ ë„ì„œë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    
    Args:
        query (str): ê²€ìƒ‰ì–´
        k (int): ë°˜í™˜í•  ê²°ê³¼ ìˆ˜ (ê¸°ë³¸ê°’ 3)
    
    Returns:
        list: ê²€ìƒ‰ ê²°ê³¼ (ì±… ì •ë³´ ë¦¬ìŠ¤íŠ¸)
    """
    search_results = []
    
    while True:
        query = query.strip()

        if not query:
            continue
            
        if query.lower() in ['q', 'quit']:
            print("\nğŸ‘‹ ê²€ìƒ‰ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break

        try:
            print(f"\n'{query}' ê²€ìƒ‰ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
            
            # HTTP ìš”ì²­ í—¤ë” ì„¤ì •
            headers = {
                "X-Naver-Client-Id": NAVER_CLIENT_ID,
                "X-Naver-Client-Secret": NAVER_CLIENT_SECRET
            }
            
            # ìš”ì²­ íŒŒë¼ë¯¸í„° ì„¤ì •
            params = {
                "query": query,
                "display": k
            }
            
            # API ìš”ì²­ ë³´ë‚´ê¸°
            response = requests.get(NAVER_BOOKS_URL, headers=headers, params=params)
            response.raise_for_status()  # ìš”ì²­ ì—ëŸ¬ í™•ì¸
            
            data = response.json()
            items = data.get("items", [])
            
            search_results = search_results + items
            print(f"\nâœ¨ ê²€ìƒ‰ ì™„ë£Œ! {len(search_results)}ê°œì˜ ê²°ê³¼ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.\n")
            
            # ì¢…ë£Œ
            break
        
        except Exception as e:
            print(f"\nâŒ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
    
    return search_results


# ê²€ìƒ‰ ê²°ê³¼ ìë£Œí˜• ì„¤ì • 
class SearchResult(BaseModel):
    """
    ì‚¬ìš©ì ì§ˆë¬¸: str
    ì•¡ì…˜: str
    ê²€ìƒ‰ í‚¤ì›Œë“œ: str
    """
    user_query: str
    action: str
    search_keywords: str


# ê²€ìƒ‰ Agent ì„¤ì • 
class AIAgent:
    def __init__(self, openai_api_key, llm_model="gpt-4o"):
        self.openai_api_key = openai_api_key
        self.llm_model = llm_model
    
    def analyze_query(self, user_query):
        """
        LLMì„ ì‚¬ìš©í•˜ì—¬ ìœ ì € ì¿¼ë¦¬ë¥¼ ë¶„ì„í•˜ê³  ê·¸ ê²°ê³¼ë¥¼ ë°˜í™˜.
        """
        llm = ChatOpenAI(
            model=self.llm_model,
            temperature=0.1,
            api_key=self.openai_api_key,
        )
        
        self.output_parser = PydanticOutputParser(
            pydantic_object=SearchResult
        )
        
        self.prompt = PromptTemplate(
            input_variables=["user_query"],
            partial_variables={
                "format_instructions": self.output_parser.get_format_instructions()
            },
            template=
            """
            ë‹¹ì‹ ì€ ë„ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” ë„ìš°ë¯¸ì…ë‹ˆë‹¤.
            ë¨¼ì € ì…ë ¥ëœ ì§ˆì˜ê°€ ë„ì„œ ê´€ë ¨ ë‚´ìš©ì¸ì§€ í™•ì¸í•˜ì„¸ìš”.

            ë„ì„œ ê´€ë ¨ ì£¼ì œ íŒë‹¨ ê¸°ì¤€:
            1. ì§ˆë¬¸ì— ë„ì„œ ì œëª©, ì €ì, ì¶œíŒì‚¬, ì¶œíŒ ì—°ë„, ì¥ë¥´ ë“±ì˜ í‚¤ì›Œë“œê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.
            2. ì§ˆë¬¸ì˜ ì˜ë„ê°€ ë„ì„œ ì •ë³´ë¥¼ ìš”êµ¬í•˜ê±°ë‚˜ ì±… ì¶”ì²œì„ ìš”ì²­í•˜ëŠ”ì§€ ë¶„ì„í•˜ì„¸ìš”.
            3. ë„ì„œ ì„ íƒ, ì„¸ë¶€ ì •ë³´, ë¦¬ë·°, í™œìš©ê³¼ ê´€ë ¨ëœ ì¼ë°˜ì ì¸ ì£¼ì œì¸ì§€ íŒë‹¨í•˜ì„¸ìš”.
            4. ì§ˆì˜ ìœ í˜•ì´ ì •ë³´ ê²€ìƒ‰í˜•ì¸ì§€, ë„ì„œ ì¶”ì²œ ì˜ë„ê°€ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.
            5. ë„ì„œì™€ ê´€ë ¨ ì—†ëŠ” ì§ˆë¬¸(ì˜ˆ: \"ì±…ìƒ ì¶”ì²œ\")ì€ ì œì™¸í•˜ì„¸ìš”.

            ë„ì„œ ê´€ë ¨ ì§ˆì˜ê°€ ì•„ë‹Œ ê²½ìš°:
            - actionì„ "not_supported"ë¡œ ì„¤ì •
            - search_keywordëŠ” ë¹ˆ ë¬¸ìì—´ë¡œ ì„¤ì •            

            ë„ì„œ ê´€ë ¨ ì§ˆì˜ì¸ ê²½ìš° ë‹¤ìŒ ì‘ì—…ì„ ìˆ˜í–‰í•˜ì„¸ìš”:
            - actionì„ "search_books"ë¡œ ì„¤ì • 
            - í‚¤ì›Œë“œ ì¶”ì¶œ: ìµœì í™” ê²€ìƒ‰ì–´ ìƒì„±

            í‚¤ì›Œë“œ ì¶”ì¶œ ê·œì¹™:
            1. í•µì‹¬ ì£¼ì œì–´ ë¶„ë¦¬
            - ë„ì„œ ê´€ë ¨ í•µì‹¬ ê°œë… ì¶”ì¶œ
            - ë³´ì¡°ì–´ ë° ì¡°ì‚¬ ì œê±°

            2. ì˜ë¯¸ë¡ ì  ìµœì í™”
            - ì „ë¬¸ ìš©ì–´ ì™„ì „ì„± ìœ ì§€
            - ê°œë… ê°„ ê´€ê³„ì„± ë³´ì¡´
            - ë§¥ë½ ì í•©ì„± í™•ë³´

            ë¶„ì„ ëŒ€ìƒ ì§ˆì˜: {user_query}

            {format_instructions}
            """,
        )

        # ì‹¤í–‰ ì²´ì¸ ìƒì„± - í”„ë¡¬í”„íŠ¸ ì²˜ë¦¬ë¶€í„° ê²°ê³¼ íŒŒì‹±ê¹Œì§€ì˜ ì „ì²´ íë¦„
        self.chain = RunnableSequence(
            first= {"user_query": RunnablePassthrough()} | self.prompt,  # ë¨¼ì € í”„ë¡¬í”„íŠ¸ ì²˜ë¦¬
            middle=[llm],  # ê·¸ ë‹¤ìŒ LLMìœ¼ë¡œ ì²˜ë¦¬
            last=self.output_parser,  # ë§ˆì§€ë§‰ìœ¼ë¡œ ê²°ê³¼ íŒŒì‹±
        )
        
        response = self.chain.invoke(user_query)  # ì§ˆë¬¸ ë¶„ì„
        print(response)
        
        return response.model_dump()  # json í˜•ì‹ìœ¼ë¡œ ë³€í˜•í˜•

# ê²°ê³¼ë¥¼ ë³´ì—¬ì£¼ëŠ” í•¨ìˆ˜ 
def display_results(results):
    """
    ê²€ìƒ‰ ê²°ê³¼ë¥¼ ìŠ¤íŠ¸ë¦¼ë¦¿ìœ¼ë¡œ ë³´ì—¬ì£¼ê¸° 
    """
    st.write(results)
        


# ì´ì „ ëŒ€í™” ê¸°ë¡ì„ ì¶œë ¥í•´ì£¼ëŠ” í•¨ìˆ˜
def print_messages():
    if "messages" in st.session_state and len(st.session_state["messages"]) > 0:
        for chat_message in st.session_state["messages"]:
            st.chat_message(chat_message.role).write(chat_message.content)


#text streaming
class StreamHandler(BaseCallbackHandler):
    def __init__ (self, container, initial_text=""):
        self.container = container
        self.text = initial_text
    
    def on_llm_new_token(self, token: str, **kwargs) -> None:
        self.text += token
        self.container.markdown(self.text)


# Streamlit Part ì‹œì‘

# Streamlit ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state["messages"] = []

# Agent ì´ˆê¸°í™”
agent = AIAgent(openai_api_key)

try: 
    # ëŒ€í™” ê¸°ë¡ ì¶œë ¥
    print_messages()
    
    # ì‚¬ìš©ìì˜ ì§ˆë¬¸ ë°›ê¸° 
    if user_input := st.chat_input("ê¶ê¸ˆí•œ ê²ƒì„ ì…ë ¥í•˜ì„¸ìš”."):
        st.chat_message("user").write(user_input)
        st.session_state["messages"].append(ChatMessage(role="user", content=user_input))
        
        # ì¿¼ë¦¬ ë¶„ì„
        print("="*30)
        print("LLMì„ í†µí•´ ì…ë ¥ ì¿¼ë¦¬ë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤...")
        result = agent.analyze_query(user_input)
        
        st.empty()
        with st.chat_message("assistant"):
            st.empty()
            stream_handler = StreamHandler(st.empty())
        
            # YouTube ê²€ìƒ‰
            if result['action'] == 'search_books':
                print("="*30)
                print("ë„ì„œ ê²€ìƒ‰ ì¤‘ì…ë‹ˆë‹¤...")
                search_results = search_books(result['search_keywords'])
                print("ê²€ìƒ‰ì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤.")

                # ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ
                if search_results:                       
                    st.write("ë„ì„œ ê²€ìƒ‰ ê²°ê³¼ì…ë‹ˆë‹¤.")
                    display_results(search_results)
                    
                    st.session_state["messages"].append(
                        ChatMessage(role="assistant", content=search_results)
                    )
                else:
                    response = "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."
                    st.write(f"{response}")
                    st.session_state["messages"].append(
                        ChatMessage(role="assistant", content=response)
                    )
            
            else:
                response = "ë„ì„œì™€ ê´€ë ¨ëœ ì§ˆë¬¸ë§Œ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                st.write(f"{response}")
                st.session_state["messages"].append(
                    ChatMessage(role="assistant", content=response)
                )

except KeyboardInterrupt:
    print("Shutting down process...")
    st.write("Shutting down process...")

except Exception as e:
    print(f"Error occurred: {e}")
    st.write(f"Error occurred: {e}")