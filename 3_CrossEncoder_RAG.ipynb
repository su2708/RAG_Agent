{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI 뉴스 RAG 시스템 구축 및 테스트\n",
    "\n",
    "이 노트북에서는 CrossEncoder를 활용한 재순위화(Reranking)가 포함된 고급 RAG 검색 시스템을 구현하고 테스트합니다.\n",
    "\n",
    "## 1. RAG 시스템 구현\n",
    "\n",
    "`AINewsRAG` 클래스는 다음과 같은 고급 검색 기능을 제공합니다:\n",
    "\n",
    "1. **하이브리드 검색**: \n",
    "   - 벡터 기반 의미 검색 (FAISS)\n",
    "   - 키워드 기반 검색 (BM25)\n",
    "   - 두 검색 결과의 가중치 기반 통합\n",
    "\n",
    "2. **CrossEncoder 재순위화**: \n",
    "   - 초기 검색 결과의 정확한 관련성 평가\n",
    "   - 쿼리-문서 쌍의 문맥 기반 평가\n",
    "   - 초기 검색 점수와 CE 점수의 가중치 기반 통합\n",
    "\n",
    "3. **유연한 가중치 조정**: \n",
    "   - 하이브리드 검색 가중치 (semantic_weight)\n",
    "   - CrossEncoder 재순위화 가중치 (ce_weight)\n",
    "\n",
    "## 2. 시스템 설정 및 파라미터\n",
    "\n",
    "### 2.1 기본 설정\n",
    "```python\n",
    "rag = AINewsRAG(\n",
    "    embedding_model=OpenAIEmbeddings(),\n",
    "    cross_encoder_name=\"BM-K/KoSimCSE-roberta-multitask\"\n",
    ")\n",
    "```\n",
    "\n",
    "### 2.2 주요 파라미터\n",
    "1. **하이브리드 검색 가중치** (semantic_weight)\n",
    "   - 의미 중심: 0.7~0.8 (문맥 이해 중요)\n",
    "   - 키워드 중심: 0.2~0.3 (정확한 매칭 중요)\n",
    "   - 균형: 0.5 (두 방식 균형)\n",
    "\n",
    "2. **CrossEncoder 가중치** (ce_weight)\n",
    "   - 강한 재순위화: 0.8 (CE 점수 중심)\n",
    "   - 중간 재순위화: 0.7 (권장값)\n",
    "   - 약한 재순위화: 0.6 (초기 순위 유지)\n",
    "\n",
    "3. **재순위화 설정**\n",
    "   - initial_fetch_k: 20 (k의 4배 권장)\n",
    "   - use_reranking: True/False\n",
    "\n",
    "## 3. 검색 프로세스\n",
    "\n",
    "### 3.1 기본 하이브리드 검색\n",
    "```python\n",
    "results = rag.hybrid_search(\n",
    "    query=\"AI 기술\",\n",
    "    k=5,\n",
    "    semantic_weight=0.7\n",
    ")\n",
    "```\n",
    "\n",
    "### 3.2 CrossEncoder 재순위화 검색\n",
    "```python\n",
    "results = rag.advanced_search(\n",
    "    query=\"AI 기술\",\n",
    "    k=5,                    # 최종 결과 수\n",
    "    semantic_weight=0.7,    # 하이브리드 검색 가중치\n",
    "    ce_weight=0.7,         # CrossEncoder 가중치\n",
    "    use_reranking=True,    # 재순위화 사용\n",
    "    initial_fetch_k=20     # 재순위화 후보 수\n",
    ")\n",
    "```\n",
    "\n",
    "## 4. 성능 최적화 가이드\n",
    "\n",
    "### 4.1 검색 품질 최적화\n",
    "- 하이브리드 검색 가중치 조정\n",
    "- CrossEncoder 가중치 조정\n",
    "- initial_fetch_k 값 설정 (k의 4~5배 권장)\n",
    "\n",
    "### 4.2 속도 최적화\n",
    "- CrossEncoder 배치 처리\n",
    "- 적절한 initial_fetch_k 설정\n",
    "- 캐싱 활용\n",
    "\n",
    "## 5. 환경 설정\n",
    "```env\n",
    "# OpenAI 설정\n",
    "OPENAI_API_KEY=your-api-key\n",
    "OPENAI_EMBEDDING_MODEL=text-embedding-3-small\n",
    "\n",
    "# 경로 설정\n",
    "VECTOR_STORE_NAME=ai_news_vectorstore\n",
    "PROCESSED_DOCS_PATH=processed_docs/processed_docs.pkl\n",
    "\n",
    "# CrossEncoder 모델\n",
    "CROSS_ENCODER_MODEL=BM-K/KoSimCSE-roberta-multitask\n",
    "```\n",
    "\n",
    "## 6. 결과 해석\n",
    "\n",
    "### 6.1 검색 결과 포맷\n",
    "- 문서 제목과 날짜\n",
    "- 관련성 점수 (정규화된 값)\n",
    "- URL 및 내용 미리보기\n",
    "- 점수 해석:\n",
    "  - 하이브리드 점수: 0~1 (높을수록 관련성 높음)\n",
    "  - CrossEncoder 점수: 0~1 (재순위화 후 최종 점수)\n",
    "\n",
    "### 6.2 성능 분석\n",
    "```python\n",
    "results_df = compare_search_results(\n",
    "    query=\"AI 교육\",\n",
    "    rag=rag,\n",
    "    k=5\n",
    ")\n",
    "```\n",
    "- 키워드 검색 vs 의미 검색 vs 하이브리드 vs CrossEncoder 결과 비교\n",
    "- 순위 변화 분석\n",
    "- 점수 분포 확인\n",
    "\n",
    "이 시스템은 문맥 기반의 정확한 검색과 키워드 기반의 정확한 매칭을 결합하여, 더 관련성 높은 검색 결과를 제공합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cross Encoder 핵심 원리**\n",
    "- 쿼리와 문서를 하나의 시퀀스로 입력: [CLS] Query [SEP] Document [SEP]\n",
    "- 관련성 있는 쌍(1)과 없는 쌍(0)으로 학습\n",
    "- 전체 문맥을 고려한 상호작용 학습\n",
    "\n",
    "**RAG에서의 실제 예시**\n",
    "```\n",
    "쿼리: \"파이썬 머신러닝 입문 방법\"\n",
    "\n",
    "1. 초기 검색 (Bi-encoder)\n",
    "   - \"자바 프로그래밍 기초\" (0.8)\n",
    "   - \"파이썬 머신러닝 가이드\" (0.75)\n",
    "   - \"R로 시작하는 통계분석\" (0.7)\n",
    "   \n",
    "2. Cross Encoder 재순위화\n",
    "   - \"파이썬 머신러닝 가이드\" (0.95) ⬆️\n",
    "   - \"R로 시작하는 통계분석\" (0.4)\n",
    "   - \"자바 프로그래밍 기초\" (0.2) ⬇️\n",
    "```\n",
    "\n",
    "**개선 효과**\n",
    "- Bi-encoder: 단순 키워드 매칭으로 \"자바...\"가 높은 점수\n",
    "- Cross Encoder: 문맥 이해로 실제 관련 문서 \"파이썬 머신러닝...\"이 상위로 이동\n",
    "- 결과: LLM에 더 관련성 높은 문서 제공 → 더 정확한 답변 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "import pickle\n",
    "import logging\n",
    "import sys\n",
    "import numpy as np\n",
    "from typing import List, Dict, Tuple\n",
    "from tqdm import tqdm\n",
    "from rank_bm25 import BM25Okapi\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "class AINewsRAG:\n",
    "    def __init__(self, embedding_model, \n",
    "                 cross_encoder_name: str = \"BM-K/KoSimCSE-roberta-multitask\"):\n",
    "        \"\"\"\n",
    "        AINewsRAG 클래스 초기화\n",
    "        \"\"\"\n",
    "        self.embeddings = embedding_model\n",
    "        self.text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=1000,\n",
    "            chunk_overlap=200,\n",
    "            length_function=len\n",
    "        )\n",
    "        self.vector_store = None\n",
    "        self.bm25 = None\n",
    "        self.processed_docs = None\n",
    "        self.doc_mapping = None\n",
    "        \n",
    "        # 로깅 설정\n",
    "        self.logger = logging.getLogger('AINewsRAG')\n",
    "        # 기존 핸들러 제거\n",
    "        if self.logger.handlers:\n",
    "            self.logger.handlers.clear()\n",
    "        \n",
    "        self.logger.setLevel(logging.INFO)\n",
    "        handler = logging.StreamHandler(sys.stdout)\n",
    "        handler.setFormatter(logging.Formatter('%(asctime)s - %(message)s'))\n",
    "        self.logger.addHandler(handler)\n",
    "        # 로그 중복 방지\n",
    "        self.logger.propagate = False\n",
    "        \n",
    "        # CrossEncoder 초기화\n",
    "        try:\n",
    "            self.cross_encoder = CrossEncoder(cross_encoder_name)\n",
    "        except Exception as e:\n",
    "            self.logger.warning(f\"CrossEncoder 초기화 실패: {str(e)}\")\n",
    "            self.cross_encoder = None\n",
    "\n",
    "    def load_vector_store(self, vector_store_path: str, processed_docs_path):\n",
    "        \"\"\"\n",
    "        벡터 스토어와 BM25 데이터를 로드합니다.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.logger.info(f\"데이터를 {vector_store_path}에서 로드합니다...\")\n",
    "            \n",
    "            # 벡터 스토어 로드\n",
    "            self.vector_store = FAISS.load_local(\n",
    "                vector_store_path,\n",
    "                self.embeddings,\n",
    "                allow_dangerous_deserialization=True\n",
    "            )\n",
    "            \n",
    "            # processed_docs 로드\n",
    "            if os.path.exists(processed_docs_path):\n",
    "                with open(processed_docs_path, 'rb') as f:\n",
    "                    self.processed_docs = pickle.load(f)\n",
    "                self.initialize_bm25(self.processed_docs)\n",
    "            \n",
    "            self.logger.info(\"로드가 완료되었습니다.\")\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"로드 중 오류 발생: {str(e)}\")\n",
    "            raise\n",
    "        \n",
    "    def rerank_with_cross_encoder(\n",
    "        self, \n",
    "        query: str, \n",
    "        initial_results: List[Tuple[Document, float]], \n",
    "        top_k: int = 5,\n",
    "        alpha: float = 0.7  # CrossEncoder 점수 가중치\n",
    "    ) -> List[Tuple[Document, float]]:\n",
    "        \"\"\"\n",
    "        CrossEncoder와 초기 검색 점수를 결합하여 재순위화를 수행합니다.\n",
    "        \n",
    "        Args:\n",
    "            alpha: CrossEncoder 점수의 가중치 (0~1)\n",
    "            1-alpha: 초기 검색 점수의 가중치\n",
    "        \"\"\"\n",
    "        pairs = [[query, doc.page_content] for doc, _ in initial_results]\n",
    "        \n",
    "        try:\n",
    "            # CrossEncoder 점수 계산\n",
    "            cross_scores = self.cross_encoder.predict(pairs)\n",
    "            \n",
    "            # 점수 정규화\n",
    "            max_cross_score = max(cross_scores)\n",
    "            norm_cross_scores = [score/max_cross_score for score in cross_scores]\n",
    "            \n",
    "            max_initial_score = max(score for _, score in initial_results)\n",
    "            norm_initial_scores = [score/max_initial_score for _, score in initial_results]\n",
    "            \n",
    "            # 가중치를 적용한 점수 결합\n",
    "            reranked = [\n",
    "                (doc, alpha * cross_score + (1-alpha) * init_score)\n",
    "                for (doc, _), cross_score, init_score \n",
    "                in zip(initial_results, norm_cross_scores, norm_initial_scores)\n",
    "            ]\n",
    "            \n",
    "            # 결과 정렬\n",
    "            reranked.sort(key=lambda x: x[1], reverse=True)\n",
    "            return reranked[:top_k]\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"재순위화 중 오류 발생: {str(e)}\")\n",
    "            return initial_results[:top_k]\n",
    "    \n",
    "    \n",
    "\n",
    "    def initialize_bm25(self, documents: List[Document]):\n",
    "        \"\"\"\n",
    "        BM25 검색 엔진을 초기화합니다.\n",
    "\n",
    "        Args:\n",
    "            documents (List[Document]): 처리된 문서 리스트\n",
    "        \"\"\"\n",
    "        self.logger.info(\"BM25 검색 엔진을 초기화합니다...\")\n",
    "        \n",
    "        tokenized_corpus = [\n",
    "            doc.page_content.lower().split() \n",
    "            for doc in documents\n",
    "        ]\n",
    "        \n",
    "        self.bm25 = BM25Okapi(tokenized_corpus)\n",
    "        self.doc_mapping = {\n",
    "            i: doc for i, doc in enumerate(documents)\n",
    "        }\n",
    "        \n",
    "        self.logger.info(\"BM25 검색 엔진 초기화가 완료되었습니다.\")\n",
    "    \n",
    "    def keyword_search(self, query: str, k: int = 5) -> List[Tuple[Document, float]]:\n",
    "        \"\"\"\n",
    "        키워드 기반 BM25 검색을 수행합니다.\n",
    "\n",
    "        Args:\n",
    "            query (str): 검색 쿼리\n",
    "            k (int): 반환할 결과 수\n",
    "\n",
    "        Returns:\n",
    "            List[Tuple[Document, float]]: (문서, 점수) 튜플의 리스트\n",
    "\n",
    "        Raises:\n",
    "            ValueError: BM25가 초기화되지 않은 경우\n",
    "        \"\"\"\n",
    "        if self.bm25 is None:\n",
    "            raise ValueError(\"BM25가 초기화되지 않았습니다.\")\n",
    "        \n",
    "        self.logger.info(f\"'{query}' 키워드 검색을 시작합니다...\")\n",
    "        \n",
    "        tokenized_query = query.lower().split()\n",
    "        bm25_scores = self.bm25.get_scores(tokenized_query)\n",
    "        \n",
    "        top_k_idx = np.argsort(bm25_scores)[-k:][::-1]\n",
    "        results = [\n",
    "            (self.doc_mapping[idx], bm25_scores[idx])\n",
    "            for idx in top_k_idx\n",
    "        ]\n",
    "        \n",
    "        self.logger.info(f\"{len(results)}개의 키워드 검색 결과를 찾았습니다.\")\n",
    "        return results\n",
    "    \n",
    "    def hybrid_search(\n",
    "            self, \n",
    "            query: str, \n",
    "            k: int = 5, \n",
    "            semantic_weight: float = 0.5\n",
    "        ) -> List[Tuple[Document, float]]:\n",
    "            \"\"\"\n",
    "            의미론적 검색과 키워드 검색을 결합한 하이브리드 검색을 수행합니다.\n",
    "            \"\"\"\n",
    "            self.logger.info(f\"'{query}' 하이브리드 검색을 시작합니다...\")\n",
    "            \n",
    "            # 의미론적 검색 수행\n",
    "            self.logger.info(f\"'{query}' 의미론적 검색을 시작합니다...\")\n",
    "            semantic_results = self.vector_store.similarity_search_with_score(query, k=k)\n",
    "            self.logger.info(f\"{len(semantic_results)}개의 의미론적 검색 결과를 찾았습니다.\")\n",
    "            \n",
    "            #키워드 기반 검색 수행\n",
    "            keyword_results = self.keyword_search(query, k=k)\n",
    "            \n",
    "            # 문서 ID를 키로 사용\n",
    "            combined_scores = {}\n",
    "            \n",
    "            # 의미론적 검색 결과 처리\n",
    "            max_semantic_score = max(score for _, score in semantic_results)\n",
    "            for doc, score in semantic_results:\n",
    "                doc_id = doc.metadata['chunk_id']\n",
    "                normalized_score = 1 - (score / max_semantic_score)\n",
    "                combined_scores[doc_id] = {\n",
    "                    'doc': doc,\n",
    "                    'score': semantic_weight * normalized_score\n",
    "                }\n",
    "            \n",
    "            # 키워드 검색 결과 처리\n",
    "            max_keyword_score = max(score for _, score in keyword_results)\n",
    "            for doc, score in keyword_results:\n",
    "                doc_id = doc.metadata['chunk_id']\n",
    "                normalized_score = score / max_keyword_score\n",
    "                if doc_id in combined_scores:\n",
    "                    combined_scores[doc_id]['score'] += (1 - semantic_weight) * normalized_score\n",
    "                else:\n",
    "                    combined_scores[doc_id] = {\n",
    "                        'doc': doc,\n",
    "                        'score': (1 - semantic_weight) * normalized_score\n",
    "                    }\n",
    "            \n",
    "            # 결과 정렬\n",
    "            sorted_results = sorted(\n",
    "                [(info['doc'], info['score']) for info in combined_scores.values()],\n",
    "                key=lambda x: x[1],\n",
    "                reverse=True\n",
    "            )[:k]\n",
    "            \n",
    "            self.logger.info(f\"{len(sorted_results)}개의 하이브리드 검색 결과를 찾았습니다.\")\n",
    "            return sorted_results\n",
    "        \n",
    "    def advanced_search(\n",
    "        self, \n",
    "        query: str, \n",
    "        k: int = 5, \n",
    "        semantic_weight: float = 0.5,     #\n",
    "        ce_weight: float = 0.7,         \n",
    "        use_reranking: bool = True,\n",
    "        initial_fetch_k: int = 20\n",
    "    ) -> List[Tuple[Document, float]]:\n",
    "        \"\"\"\n",
    "        하이브리드 검색에 재순위화를 추가한 고급 검색을 수행합니다.\n",
    "\n",
    "        Args:\n",
    "            query: 검색 쿼리\n",
    "            k: 최종 반환할 결과 수\n",
    "            semantic_weight: 하이브리드 검색에서 의미론적 검색의 가중치 (0~1)\n",
    "                        - 0: 키워드 검색만 사용\n",
    "                        - 1: 의미 검색만 사용\n",
    "            ce_weight: CrossEncoder 재순위화 점수의 가중치 (0.5~0.9)\n",
    "                    - 높을수록 CrossEncoder 점수를 더 중요하게 고려\n",
    "                    - 기본값 0.7 권장\n",
    "            use_reranking: CrossEncoder 재순위화 사용 여부\n",
    "            initial_fetch_k: 재순위화를 위한 초기 검색 결과 수\n",
    "\n",
    "        Returns:\n",
    "            검색 결과 리스트 [(Document, score)]\n",
    "\n",
    "        Raises:\n",
    "            ValueError: 가중치 값이 범위를 벗어난 경우\n",
    "        \"\"\"\n",
    "        # 가중치 값 검증\n",
    "        if not 0 <= semantic_weight <= 1:\n",
    "            raise ValueError(\"semantic_weight는 0과 1 사이의 값이어야 합니다.\")\n",
    "        \n",
    "        if not 0.5 <= ce_weight <= 0.9:\n",
    "            self.logger.warning(\n",
    "                f\"권장 범위(0.5~0.9)를 벗어난 ce_weight: {ce_weight}\"\n",
    "            )\n",
    "        \n",
    "        self.logger.info(\n",
    "            f\"고급 검색 시작 - 쿼리: '{query}', \"\n",
    "            f\"의미검색 가중치: {semantic_weight}, \"\n",
    "            f\"CE 가중치: {ce_weight}\"\n",
    "        )\n",
    "\n",
    "        # 1단계: 하이브리드 검색으로 후보 문서 추출\n",
    "        initial_k = initial_fetch_k if use_reranking else k\n",
    "        initial_results = self.hybrid_search(\n",
    "            query=query,\n",
    "            k=initial_k,\n",
    "            semantic_weight=semantic_weight\n",
    "        )\n",
    "\n",
    "        # 2단계: CrossEncoder로 재순위화 (선택적)\n",
    "        if use_reranking and self.cross_encoder:\n",
    "            final_results = self.rerank_with_cross_encoder(\n",
    "                query=query,\n",
    "                initial_results=initial_results,\n",
    "                top_k=k,\n",
    "                alpha=ce_weight  # CrossEncoder 가중치 전달\n",
    "            )\n",
    "        else:\n",
    "            final_results = initial_results[:k]\n",
    "\n",
    "        self.logger.info(\n",
    "            f\"검색 완료: {len(final_results)}개 결과, \"\n",
    "            f\"최고 점수: {final_results[0][1]:.4f}\"\n",
    "        )\n",
    "        \n",
    "        return final_results\n",
    "\n",
    "    def format_search_results(\n",
    "        self, \n",
    "        results: List[Tuple[Document, float]], \n",
    "        show_score: bool = True\n",
    "    ) -> str:\n",
    "        \"\"\"검색 결과를 보기 좋게 포맷팅합니다.\"\"\"\n",
    "        output = []\n",
    "        for i, (doc, score) in enumerate(results, 1):\n",
    "            output.append(f\"\\n{'='*80}\")\n",
    "            output.append(f\"검색 결과 {i}/{len(results)}\")\n",
    "            output.append(f\"제목: {doc.metadata['title']}\")\n",
    "            output.append(f\"날짜: {doc.metadata['date']}\")\n",
    "            if show_score:\n",
    "                output.append(f\"관련도 점수: {score:.4f}\")\n",
    "            output.append(f\"URL: {doc.metadata['url']}\")\n",
    "            output.append(f\"{'-'*40}\")\n",
    "            output.append(f\"내용:\\n{doc.page_content[:300]}...\")\n",
    "        \n",
    "        return \"\\n\".join(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAG 고급 검색 시스템 테스트 및 검색 방법에 따른 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at BM-K/KoSimCSE-roberta-multitask and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-28 11:46:47,944 - 데이터를 ai_news_vectorstore에서 로드합니다...\n",
      "2024-11-28 11:46:50,142 - BM25 검색 엔진을 초기화합니다...\n",
      "2024-11-28 11:46:55,059 - BM25 검색 엔진 초기화가 완료되었습니다.\n",
      "2024-11-28 11:46:55,116 - 로드가 완료되었습니다.\n",
      "2024-11-28 11:46:55,119 - 고급 검색 시작 - 쿼리: '최신 AI 기술 동향', 의미검색 가중치: 0.7, CE 가중치: 0.7\n",
      "2024-11-28 11:46:55,119 - '최신 AI 기술 동향' 하이브리드 검색을 시작합니다...\n",
      "2024-11-28 11:46:55,119 - '최신 AI 기술 동향' 의미론적 검색을 시작합니다...\n",
      "2024-11-28 11:46:55,419 - 20개의 의미론적 검색 결과를 찾았습니다.\n",
      "2024-11-28 11:46:55,419 - '최신 AI 기술 동향' 키워드 검색을 시작합니다...\n",
      "2024-11-28 11:46:55,478 - 20개의 키워드 검색 결과를 찾았습니다.\n",
      "2024-11-28 11:46:55,478 - 20개의 하이브리드 검색 결과를 찾았습니다.\n",
      "2024-11-28 11:47:04,002 - 검색 완료: 5개 결과, 최고 점수: 0.9884\n",
      "\n",
      "================================================================================\n",
      "검색 결과 1/5\n",
      "제목: 개인정보위, 자율주행 AI 학습 영상 '개인정보보호 원칙' 공식 문서화\n",
      "날짜: 2024.10.14 16:52\n",
      "관련도 점수: 0.9884\n",
      "URL: https://www.aitimes.com/news/articleView.html?idxno=164202\n",
      "----------------------------------------\n",
      "내용:\n",
      "이번에 공개한 안내서는 현행 법령과 최신 국내외 기술 동향 등을 종합 반영해 각계 의견수렴을 통해 마련한 것으로, 앞으로 관련 법령의 제정 및 개정이나 AI 기술 발전에 따라 지속 개선-보완할 예정이다.\n",
      "양청삼 개인정보정책국장은 “AI 발전에 따라 자율주행차, 로봇 등 이동형 영상정보처리기기가 미래 산업 경쟁력의 핵심이 될 것”이라며 \"관련 제품, 서비스 개발자 등은 이번 안내서를 참조해 정보주체에 대한 권리침해가 발생하지 않도록 세심한 주의를 기울여 글로벌 차원의 경쟁력을 강화할 수 있기를 기대한다”라고 말했다.\n",
      "안내서는 개인정보...\n",
      "\n",
      "================================================================================\n",
      "검색 결과 2/5\n",
      "제목: \"AI 최신 트렌드 배우러 오세요\"\n",
      "날짜: 2020.06.17 11:37\n",
      "관련도 점수: 0.9595\n",
      "URL: https://www.aitimes.com/news/articleView.html?idxno=129545\n",
      "----------------------------------------\n",
      "내용:\n",
      "\"AI 최신 트렌드 배우러 오세요\"\n",
      " 인공지능(AI) 최신 트렌드 및 관련 이슈와 업계 전문가의 강연을 들을 수 있게 됐다.\n",
      "한국미래기술교육연구원(대표 박희정)은 오는 7월 15일 서울 여의도 전경련회관 사파이어홀에서 'AI 최신 트렌드 및 이슈 분석 세미나'를 개최한다고 밝혔다.\n",
      "한국미래기술교육 연구원은 인공지능(AI) 관련 최신 이슈인 △인공일반지능(AGI) 도입과 적용기술 △AI경량화 기술 온 디바이스 AI, 딥러닝 경량화 기술과 적용방안 △XAI기반의 비정형 데이터 처리 및 자동화 플랫폼 구현방안 △인공신경망, 뉴로모픽 SN...\n",
      "\n",
      "================================================================================\n",
      "검색 결과 3/5\n",
      "제목: 빅테크에서 확산되는 해고 바람...11월 3주\n",
      "날짜: 2022.11.21 07:00\n",
      "관련도 점수: 0.9507\n",
      "URL: https://www.aitimes.com/news/articleView.html?idxno=148013\n",
      "----------------------------------------\n",
      "내용:\n",
      "몸집 줄이려고 무리하게 다이어트하다간 아예 건강을 잃게 될 수도 있으니 유의해야겠지요. 이어서 지난주 기술 동향 전해드립니다.\n",
      "기술 동향\n",
      "◼ 인텔과 AMD, 엔비디아, IBM, 구글 등 주요 반도체 기업이 최근 고성능 컴퓨팅(HPC)과 AI를 위한 차세대 칩을 잇달아 공개했습니다. 차세대 슈퍼컴퓨팅 반도체 시장을 둘러싼 주도권 경쟁이 한층 뜨거워졌습니다.\n",
      "몇 년 전까지만 해도 CPU는 인텔과 AMD가 경쟁하고, GPU는 엔비디아가 거의 독점하는 구도였습니다. 그러나 최근 엔비디아가 데이터 센터를 겨냥해 CPU를 내놓고, 이에 질세라...\n",
      "\n",
      "================================================================================\n",
      "검색 결과 4/5\n",
      "제목: 지능정보산업협회, 조찬 포럼서 AI 산업 동향 공유\n",
      "날짜: 2023.04.11 19:00\n",
      "관련도 점수: 0.9478\n",
      "URL: https://www.aitimes.com/news/articleView.html?idxno=150475\n",
      "----------------------------------------\n",
      "내용:\n",
      "지능정보산업협회, 조찬 포럼서 AI 산업 동향 공유\n",
      " 지능정보산업협회(AIIA)가 11일 JW 메리어트 호텔에서 제27회 조찬포럼을 진행했다.\n",
      "이는 지능정보산업협회 회원사를 중심으로 인공지능(AI) 산업 이슈 및 동향 등을 자유롭게 공유하며 논의하는 자리다.\n",
      "이 자리에서는 ▲이경진 카카오엔터프라이즈 부사장의 '챗GPT 등장에서 보는 클라우드 인프라 구현 동향' ▲변계풍 이스트소프트 본부장의 '생성형 AI 기술과 사업적 활용 현황' ▲지진우 글라우드 대표의 'B2B 디지털 헬스케어 시장진입시 고려사항' 등 강연이 열렸다.\n",
      "이주영 기자...\n",
      "\n",
      "================================================================================\n",
      "검색 결과 5/5\n",
      "제목: 과기정통부-구글 \"국내 AI 인재 양성에 힘 모을 것\"\n",
      "날짜: 2023.07.13 20:26\n",
      "관련도 점수: 0.9405\n",
      "URL: https://www.aitimes.com/news/articleView.html?idxno=152413\n",
      "----------------------------------------\n",
      "내용:\n",
      "이어 이세영 뤼튼 대표, 신정규 래블업 대표, 카카오 헬스케어 신수용 소장, 한재준 삼성전자 종합기술원(SAIT) 마스터 등 업계 대표가 '패널 토크'를 진행했다.\n",
      "행사장에는 최신 AI 기술을 직접 체험할 수 있는 데모존을 준비, 최신 기술을 선보였다.\n",
      "이번 행사는 3일동안 ‘모두를 위한 AI’ ‘비즈니스를 위한 AI’ ‘학생을 위한 AI’라는 주제로 진행한다. 첫날은 구글 및 국내 연구자를 중심으로 AI  최신 연구 동향 및 방향성을 선보였다.\n",
      "14일에는 구글 연례 개발자 행사(I/O 2023)에서 발표된 내용 중 안드로이드, 구...\n"
     ]
    }
   ],
   "source": [
    "# 환경 변수 로드\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "# 임베딩 모델 초기화\n",
    "embedding_model = OpenAIEmbeddings(\n",
    "    model=os.getenv(\"OPENAI_EMBEDDING_MODEL\", \"text-embedding-3-small\")\n",
    ")\n",
    "\n",
    "# RAG 시스템 초기화\n",
    "rag = AINewsRAG(embedding_model, os.getenv(\"CROSS_ENCODER_MODEL\"))\n",
    "\n",
    "# 벡터 스토어 로드\n",
    "vector_store_path = os.getenv(\"VECTOR_STORE_NAME\")\n",
    "processed_docs_path = os.getenv(\"PROCESSED_DOCS_PATH\")\n",
    "rag.load_vector_store(vector_store_path, processed_docs_path)\n",
    "\n",
    "# 검색 수행\n",
    "query = \"최신 AI 기술 동향\"\n",
    "\n",
    "# CrossEncoder를 활용한 고급 검색\n",
    "results = rag.advanced_search(\n",
    "    query=query,\n",
    "    k=5,                     # 최종 결과 수\n",
    "    semantic_weight=0.7,     # 하이브리드 검색 가중치\n",
    "    ce_weight=0.7,          # CrossEncoder 가중치\n",
    "    use_reranking=True,     # 재순위화 사용\n",
    "    initial_fetch_k=20      # 재순위화 후보 수\n",
    ")\n",
    "\n",
    "# 검색 결과 출력\n",
    "formatted_results = rag.format_search_results(results)\n",
    "print(formatted_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 검색 결과 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at BM-K/KoSimCSE-roberta-multitask and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-28 11:52:04,603 - 데이터를 ai_news_vectorstore에서 로드합니다...\n",
      "2024-11-28 11:52:06,025 - BM25 검색 엔진을 초기화합니다...\n",
      "2024-11-28 11:52:11,095 - BM25 검색 엔진 초기화가 완료되었습니다.\n",
      "2024-11-28 11:52:11,143 - 로드가 완료되었습니다.\n",
      "2024-11-28 11:52:11,153 - 고급 검색 시작 - 쿼리: 'AI 교육', 의미검색 가중치: 0.0, CE 가중치: 0.7\n",
      "2024-11-28 11:52:11,153 - 'AI 교육' 하이브리드 검색을 시작합니다...\n",
      "2024-11-28 11:52:11,153 - 'AI 교육' 의미론적 검색을 시작합니다...\n",
      "2024-11-28 11:52:11,725 - 5개의 의미론적 검색 결과를 찾았습니다.\n",
      "2024-11-28 11:52:11,725 - 'AI 교육' 키워드 검색을 시작합니다...\n",
      "2024-11-28 11:52:11,773 - 5개의 키워드 검색 결과를 찾았습니다.\n",
      "2024-11-28 11:52:11,773 - 5개의 하이브리드 검색 결과를 찾았습니다.\n",
      "2024-11-28 11:52:11,773 - 검색 완료: 5개 결과, 최고 점수: 1.0000\n",
      "2024-11-28 11:52:11,773 - 고급 검색 시작 - 쿼리: 'AI 교육', 의미검색 가중치: 1.0, CE 가중치: 0.7\n",
      "2024-11-28 11:52:11,779 - 'AI 교육' 하이브리드 검색을 시작합니다...\n",
      "2024-11-28 11:52:11,779 - 'AI 교육' 의미론적 검색을 시작합니다...\n",
      "2024-11-28 11:52:12,154 - 5개의 의미론적 검색 결과를 찾았습니다.\n",
      "2024-11-28 11:52:12,160 - 'AI 교육' 키워드 검색을 시작합니다...\n",
      "2024-11-28 11:52:12,210 - 5개의 키워드 검색 결과를 찾았습니다.\n",
      "2024-11-28 11:52:12,210 - 5개의 하이브리드 검색 결과를 찾았습니다.\n",
      "2024-11-28 11:52:12,210 - 검색 완료: 5개 결과, 최고 점수: 0.0572\n",
      "2024-11-28 11:52:12,210 - 'AI 교육' 하이브리드 검색을 시작합니다...\n",
      "2024-11-28 11:52:12,210 - 'AI 교육' 의미론적 검색을 시작합니다...\n",
      "2024-11-28 11:52:12,522 - 5개의 의미론적 검색 결과를 찾았습니다.\n",
      "2024-11-28 11:52:12,522 - 'AI 교육' 키워드 검색을 시작합니다...\n",
      "2024-11-28 11:52:12,578 - 5개의 키워드 검색 결과를 찾았습니다.\n",
      "2024-11-28 11:52:12,587 - 5개의 하이브리드 검색 결과를 찾았습니다.\n",
      "2024-11-28 11:52:12,588 - 고급 검색 시작 - 쿼리: 'AI 교육', 의미검색 가중치: 0.5, CE 가중치: 0.6\n",
      "2024-11-28 11:52:12,590 - 'AI 교육' 하이브리드 검색을 시작합니다...\n",
      "2024-11-28 11:52:12,593 - 'AI 교육' 의미론적 검색을 시작합니다...\n",
      "2024-11-28 11:52:13,095 - 20개의 의미론적 검색 결과를 찾았습니다.\n",
      "2024-11-28 11:52:13,095 - 'AI 교육' 키워드 검색을 시작합니다...\n",
      "2024-11-28 11:52:13,126 - 20개의 키워드 검색 결과를 찾았습니다.\n",
      "2024-11-28 11:52:13,126 - 20개의 하이브리드 검색 결과를 찾았습니다.\n",
      "2024-11-28 11:52:19,831 - 검색 완료: 5개 결과, 최고 점수: 0.9744\n",
      "\n",
      "검색어: AI 교육\n",
      "\n",
      "검색 결과 비교:\n",
      "+------+--------------------------------------------------------+-------------+---------------------------------------------------------------------+---------------+--------------------------------------------------------+-----------------+------------------------------------------------------+-------------------+\n",
      "| 순위 |                      키워드_제목                       | 키워드_점수 |                            의미론적_제목                            | 의미론적_점수 |                    하이브리드_제목                     | 하이브리드_점수 |                  CrossEncoder_제목                   | CrossEncoder_점수 |\n",
      "+------+--------------------------------------------------------+-------------+---------------------------------------------------------------------+---------------+--------------------------------------------------------+-----------------+------------------------------------------------------+-------------------+\n",
      "|  1   |          KT, 초중고 AI 코딩 교육 활성화 나서           |   1.0000    |        한국AI교육협회, 유럽 인터넷은행 직원 대상 AI교육 진행        |    0.0572     |          KT, 초중고 AI 코딩 교육 활성화 나서           |     0.5000      |  엔백스-이모션웨이브, AI 창작 플랫폼으로 음악 공연   |      0.9744       |\n",
      "|  2   | 엘리스그룹, 미국 에듀테크 컨퍼런스 'ISTE Live 24' 참가 |   0.9861    | 중국, 대입 시험 채점에 AI 테스트...\"인간보다 AI가 필기체 인식 정확\" |    0.0451     | 엘리스그룹, 미국 에듀테크 컨퍼런스 'ISTE Live 24' 참가 |     0.4931      |   이스트소프트, 한림대 ‘AI 챗봇 서비스’ 제공 계약    |      0.9672       |\n",
      "|  3   |  정부, 초ㆍ중등학교에 인공지능(AI) 교육 기반 마련한다  |   0.9745    |        KT-광운인공지능고, AI 교육 커리큘럼·플랫폼 구축 협력         |    0.0092     |  정부, 초ㆍ중등학교에 인공지능(AI) 교육 기반 마련한다  |     0.4873      | 정부, 초ㆍ중등학교에 인공지능(AI) 교육 기반 마련한다 |      0.9549       |\n",
      "|  4   |   엔백스-이모션웨이브, AI 창작 플랫폼으로 음악 공연    |   0.9549    |        KT-서울시교육청, AI 인재양성 협력...자격시험 등 추진         |    0.0081     |   엔백스-이모션웨이브, AI 창작 플랫폼으로 음악 공연    |     0.4775      |     미디어젠-부산외대, 교육용 AI 플랫폼 확장 MOU     |      0.9548       |\n",
      "|  5   |   크라우드웍스, 기업 대상 '실무형 AI 활용 교육' 론칭   |   0.9534    |    고등학교 34곳에서 인공지능 배운다...내년부터 수업의 15% 편성     |    0.0000     |   크라우드웍스, 기업 대상 '실무형 AI 활용 교육' 론칭   |     0.4767      |  크라우드웍스, 기업 대상 '실무형 AI 활용 교육' 론칭  |      0.9533       |\n",
      "+------+--------------------------------------------------------+-------------+---------------------------------------------------------------------+---------------+--------------------------------------------------------+-----------------+------------------------------------------------------+-------------------+\n",
      "\n",
      "결과 분석:\n",
      "\n",
      "총 unique 문서 수: 12\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "def compare_search_results(query: str, rag: AINewsRAG, k: int = 5):\n",
    "   \"\"\"\n",
    "   다양한 검색 방식의 결과를 비교하여 표로 정리합니다.\n",
    "   \"\"\"\n",
    "   # 1. 키워드 검색 중심\n",
    "   keyword_focused = rag.advanced_search(\n",
    "       query=query,\n",
    "       k=k,\n",
    "       semantic_weight=0.0,\n",
    "       use_reranking=False\n",
    "   )\n",
    "   \n",
    "   # 2. 의미론적 검색 중심\n",
    "   semantic_focused = rag.advanced_search(\n",
    "       query=query,\n",
    "       k=k,\n",
    "       semantic_weight=1.0,\n",
    "       use_reranking=False\n",
    "   )\n",
    "   \n",
    "   \n",
    "   # 3. 하이브리드 검색 \n",
    "   hybrid_results = rag.hybrid_search(query, k=k, semantic_weight=0.5)\n",
    "   \n",
    "   \n",
    "   # 4. CrossEncoder 재순위화 검색\n",
    "   advanced_results = rag.advanced_search(\n",
    "       query=query,\n",
    "       k=k,\n",
    "       semantic_weight=0.5,\n",
    "       ce_weight=0.7,\n",
    "       use_reranking=True,\n",
    "       initial_fetch_k=20\n",
    "   )\n",
    "   \n",
    "   \n",
    "   # 결과를 DataFrame으로 변환\n",
    "   results = []\n",
    "   \n",
    "   for idx in range(k):\n",
    "       row = {\"순위\": idx + 1}\n",
    "       \n",
    "       # 키워드 중심 결과\n",
    "       if idx < len(keyword_focused):\n",
    "           doc, score = keyword_focused[idx]\n",
    "           row.update({\n",
    "               \"키워드_제목\": doc.metadata['title'],\n",
    "               \"키워드_점수\": f\"{score:.4f}\"\n",
    "           })\n",
    "           \n",
    "        \n",
    "        # 의미론적 중심 결과\n",
    "       if idx < len(semantic_focused):\n",
    "           doc, score = semantic_focused[idx]\n",
    "           row.update({\n",
    "               \"의미론적_제목\": doc.metadata['title'],\n",
    "               \"의미론적_점수\": f\"{score:.4f}\"\n",
    "           })\n",
    "           \n",
    "           \n",
    "       # 하이브리드 검색 결과\n",
    "       if idx < len(hybrid_results):\n",
    "           doc, score = hybrid_results[idx]\n",
    "           row.update({\n",
    "               \"하이브리드_제목\": doc.metadata['title'],\n",
    "               \"하이브리드_점수\": f\"{score:.4f}\"\n",
    "           })\n",
    "           \n",
    "       # CrossEncoder 결과\n",
    "       if idx < len(advanced_results):\n",
    "           doc, score = advanced_results[idx]\n",
    "           row.update({\n",
    "               \"CrossEncoder_제목\": doc.metadata['title'],\n",
    "               \"CrossEncoder_점수\": f\"{score:.4f}\"\n",
    "           })\n",
    "           \n",
    "       \n",
    "       results.append(row)\n",
    "   \n",
    "   # DataFrame 생성\n",
    "   df = pd.DataFrame(results)\n",
    "   \n",
    "   # 표 출력\n",
    "   print(f\"\\n검색어: {query}\")\n",
    "   print(\"\\n검색 결과 비교:\")\n",
    "   print(tabulate(df, headers='keys', tablefmt='pretty', showindex=False))\n",
    "   \n",
    "   # 결과 분석\n",
    "   print(\"\\n결과 분석:\")\n",
    "   \n",
    "   # 중복 문서 분석\n",
    "   all_titles = []\n",
    "   for results in [hybrid_results, advanced_results, semantic_focused, keyword_focused]:\n",
    "       all_titles.extend([doc.metadata['title'] for doc, _ in results])\n",
    "   \n",
    "   unique_titles = set(all_titles)\n",
    "   print(f\"\\n총 unique 문서 수: {len(unique_titles)}\")\n",
    "   \n",
    "   return df\n",
    "\n",
    "\n",
    "# 환경 변수 로드\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "# 임베딩 모델 초기화\n",
    "embedding_model = OpenAIEmbeddings(\n",
    "    model=os.getenv(\"OPENAI_EMBEDDING_MODEL\", \"text-embedding-3-small\")\n",
    ")\n",
    "\n",
    "# RAG 시스템 초기화\n",
    "rag = AINewsRAG(embedding_model, os.getenv(\"CROSS_ENCODER_MODEL\"))\n",
    "\n",
    "# 벡터 스토어 로드\n",
    "vector_store_path = os.getenv(\"VECTOR_STORE_NAME\")\n",
    "processed_docs_path = os.getenv(\"PROCESSED_DOCS_PATH\")\n",
    "rag.load_vector_store(vector_store_path, processed_docs_path)\n",
    "\n",
    "# 검색 수행\n",
    "query = \"AI 교육\"\n",
    "results_df = compare_search_results(query, rag, k=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG_Agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
