{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2ë‹¨ê³„:**\n",
    "\n",
    "- ìœ íˆ¬ë¸Œ AI ë‚´ìš© ê²€ìƒ‰ Agent ì¶”ê°€\n",
    "    - ìœ íˆ¬ë¸Œ API í™œìš©\n",
    "    - ì˜ˆì‹œ ì…ë ¥ í”„ë¡¬í”„íŠ¸ : AI ë‰´ìŠ¤ê´€ë ¨ ì˜ìƒì„ ì•Œë ¤ì¤˜\n",
    "    - Agentë¥¼ í†µí•´ì„œ ìœ íˆ¬ë¸Œ APIë¥¼ í†µí•´ ë‰´ìŠ¤ ê²€ìƒ‰ í›„ ê²€ìƒ‰ ëœ ë‚´ìš©ì„ í”„ë¡¬í”„íŠ¸ì— ë„£ì–´ì„œ ì•Œë ¤ì£¼ê¸°\n",
    "        - streamlit ìœ íˆ¬ë¸Œ ì˜ìƒ í™”ë©´ ê¹Œì§€ ê°™ì´ ë³´ì—¬ì£¼ê¸° (ì¬ìƒí•  ìˆ˜ ìˆëŠ”)\n",
    "    - AgentëŠ” ìœ ì €ì˜ ì¿¼ë¦¬ë¥¼ LLMì´ ë¶„ì„í•´ì„œ íŠ¹ì • í•¨ìˆ˜ë¥¼ ì‹¤í–‰\n",
    "    - **ê³µì‹ë¬¸ì„œ ì°¸ê³ í•´ì„œ Agentë‚´ìš© í•™ìŠµí›„ ì½”ë“œí™” (ë² ìŠ¤íŠ¸)**\n",
    "        - Quick Start (ê°€ì´ë“œ ì½”ë“œ)\n",
    "        - Lanchain : ì•ˆë°°ì› ë‹¤í•˜ë”ë¼ë„ ìŠ¤ìŠ¤ë¡œ ì°¾ì•„ì„œ í•  ìˆ˜ ìˆì–´ì•¼í•œë‹¤.\n",
    "        - App\n",
    "\n",
    "### ì•„ì´ë””ì–´ ì •ë¦¬\n",
    "1. ì‚¬ìš©ìì˜ ì§ˆë¬¸ ì…ë ¥\n",
    "2. ì§ˆë¬¸ì„ LLMìœ¼ë¡œ ë³´ë‚´ ê²€ìƒ‰ í‚¤ì›Œë“œ ë¶„ì„\n",
    "3. ê²€ìƒ‰ í‚¤ì›Œë“œì— ë§ëŠ” tool ì„¤ì •\n",
    "4. tool ë™ì‘ ìˆ˜í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import googleapiclient.discovery\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain_core.tools import BaseTool, tool\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableSequence\n",
    "from Keyword_Hybrid_RAG import AINewsRAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "import pickle\n",
    "import logging\n",
    "import sys\n",
    "import numpy as np\n",
    "from typing import List, Dict, Tuple\n",
    "from tqdm import tqdm\n",
    "from rank_bm25 import BM25Okapi\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-12 19:12:27,979 - ë°ì´í„°ë¥¼ ai_news_vectorstoreì—ì„œ ë¡œë“œí•©ë‹ˆë‹¤...\n",
      "2024-12-12 19:12:29,610 - BM25 ê²€ìƒ‰ ì—”ì§„ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤...\n",
      "2024-12-12 19:12:33,472 - BM25 ê²€ìƒ‰ ì—”ì§„ ì´ˆê¸°í™”ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "2024-12-12 19:12:33,548 - ë¡œë“œê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "âœ… ê¸°ì¡´ ë²¡í„° ìŠ¤í† ì–´ë¥¼ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "\n",
    "# í™˜ê²½ ë³€ìˆ˜ì—ì„œ ê²½ë¡œ ê°€ì ¸ì˜¤ê¸°\n",
    "vector_store_path = os.getenv(\"VECTOR_STORE_NAME\", \"ai_news_vectorstore\")\n",
    "news_dir = os.getenv(\"NEWS_FILE_PATH\", \"./ai_news\")\n",
    "processed_doc_path = os.getenv(\"PROCESSED_DOCS_PATH\", \"processed_docs/processed_docs.pkl\")\n",
    "\n",
    "# ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™” \n",
    "embedding_model = OpenAIEmbeddings(\n",
    "    model=os.getenv(\"OPENAI_EMBEDDING_MODEL\", \"text-embedding-3-small\")\n",
    ")\n",
    "\n",
    "# RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”\n",
    "rag = AINewsRAG(embedding_model)\n",
    "\n",
    "try:\n",
    "    # ê¸°ì¡´ ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ ì‹œë„\n",
    "    rag.load_vector_store(vector_store_path, processed_doc_path)\n",
    "    print(\"âœ… ê¸°ì¡´ ë²¡í„° ìŠ¤í† ì–´ë¥¼ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ ì‹¤íŒ¨: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def search_news(query: str, rag: AINewsRAG, k: int = 5):\n",
    "    \"\"\"\n",
    "    í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ë°©ì‹ìœ¼ë¡œ AI ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤ë‹¤.\n",
    "    \"\"\"\n",
    "    search_mode = \"hybrid\" # ê²€ìƒ‰ ë°©ì‹ ë³€ê²½ì€ 'mode [semantic/keyword/hybrid]'ë¥¼ ì…ë ¥í•˜ì„¸ìš”.\n",
    "    while True:\n",
    "        query = query.strip()\n",
    "\n",
    "        if not query:\n",
    "            continue\n",
    "            \n",
    "        if query.lower() in ['q', 'quit']:\n",
    "            print(\"\\nğŸ‘‹ ê²€ìƒ‰ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.\")\n",
    "            break\n",
    "            \n",
    "        if query.lower().startswith('mode '):\n",
    "            mode = query.split()[1].lower()\n",
    "            if mode in ['semantic', 'keyword', 'hybrid']:\n",
    "                search_mode = mode\n",
    "                print(f\"\\nâœ… ê²€ìƒ‰ ëª¨ë“œë¥¼ '{mode}'ë¡œ ë³€ê²½í–ˆìŠµë‹ˆë‹¤.\")\n",
    "            else:\n",
    "                print(\"\\nâŒ ì˜ëª»ëœ ê²€ìƒ‰ ëª¨ë“œì…ë‹ˆë‹¤. semantic/keyword/hybrid ì¤‘ ì„ íƒí•˜ì„¸ìš”.\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            print(f\"\\n'{query}' ê²€ìƒ‰ì„ ì‹œì‘í•©ë‹ˆë‹¤... (ëª¨ë“œ: {search_mode})\")\n",
    "            \n",
    "            if search_mode == \"hybrid\":\n",
    "                results = rag.hybrid_search(query, k=k, semantic_weight=0.5)\n",
    "            elif search_mode == \"semantic\":\n",
    "                results = rag.vector_store.similarity_search_with_score(query, k=k)\n",
    "            else:  # keyword\n",
    "                results = rag.keyword_search(query, k=k)\n",
    "            \n",
    "            print(f\"\\nâœ¨ ê²€ìƒ‰ ì™„ë£Œ! {len(results)}ê°œì˜ ê²°ê³¼ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.\\n\")\n",
    "            \n",
    "            # ê²°ê³¼ ì¶œë ¥\n",
    "            for i, (doc, score) in enumerate(results, 1):\n",
    "                print(f\"\\n{'='*80}\")\n",
    "                print(f\"ê²€ìƒ‰ ê²°ê³¼ {i}/{len(results)}\")\n",
    "                print(f\"ì œëª©: {doc.metadata['title']}\")\n",
    "                print(f\"ë‚ ì§œ: {doc.metadata['date']}\")\n",
    "                if search_mode == \"hybrid\":\n",
    "                    print(f\"í†µí•© ì ìˆ˜: {score:.4f}\")\n",
    "                elif search_mode == \"semantic\":\n",
    "                    print(f\"ìœ ì‚¬ë„ ì ìˆ˜: {1 - (score/2):.4f}\")\n",
    "                else:\n",
    "                    print(f\"BM25 ì ìˆ˜: {score:.4f}\")\n",
    "                print(f\"URL: {doc.metadata['url']}\")\n",
    "                print(f\"{'-'*40}\")\n",
    "                print(f\"ë‚´ìš©:\\n{doc.page_content[:300]}...\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"\\nâŒ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def search_video(query, youtube_api_key, max_results=5):\n",
    "        \"\"\"\n",
    "        YouTube APIë¥¼ ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰.\n",
    "        \"\"\"\n",
    "        youtube = googleapiclient.discovery.build(\n",
    "            \"youtube\", \"v3\", developerKey=youtube_api_key\n",
    "        )\n",
    "\n",
    "        request = youtube.search().list(\n",
    "            part=\"snippet\",\n",
    "            q=query,\n",
    "            type=\"video\",\n",
    "            maxResults=max_results\n",
    "        )\n",
    "        response = request.execute()\n",
    "\n",
    "        results = [\n",
    "            {\n",
    "                \"title\": item[\"snippet\"][\"title\"],\n",
    "                \"description\": item[\"snippet\"][\"description\"],\n",
    "                \"video_id\": item[\"id\"][\"videoId\"]\n",
    "            }\n",
    "            for item in response.get(\"items\", [])\n",
    "        ]\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [search_news, search_video]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SearchResult(BaseModel):\n",
    "    \"\"\"\n",
    "    ì‚¬ìš©ì ì§ˆë¬¸: str\n",
    "    ì•¡ì…˜: str\n",
    "    ê²€ìƒ‰ í‚¤ì›Œë“œ: str\n",
    "    tool ì„¤ì •: str\n",
    "    \"\"\"\n",
    "    user_query: str\n",
    "    action: str\n",
    "    search_keywords: str\n",
    "    tool: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SearchAgent:\n",
    "    def __init__(self, openai_api_key, youtube_api_key, llm_model=\"gpt-4o\"):\n",
    "        self.openai_api_key = openai_api_key\n",
    "        self.youtube_api_key = youtube_api_key\n",
    "        self.llm_model = llm_model\n",
    "        self.rag = AINewsRAG(\n",
    "            OpenAIEmbeddings(\n",
    "                model=os.getenv(\"OPENAI_EMBEDDING_MODEL\", \"text-embedding-3-small\")\n",
    "            )\n",
    "        )\n",
    "        \n",
    "    @tool\n",
    "    def search_news(self, query: str, k: int = 5):\n",
    "        \"\"\"\n",
    "        í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ë°©ì‹ìœ¼ë¡œ AI ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤ë‹¤.\n",
    "        \"\"\"\n",
    "        search_mode = \"hybrid\" # ê²€ìƒ‰ ë°©ì‹ ë³€ê²½ì€ 'mode [semantic/keyword/hybrid]'ë¥¼ ì…ë ¥í•˜ì„¸ìš”.\n",
    "        while True:\n",
    "            query = query.strip()\n",
    "\n",
    "            if not query:\n",
    "                continue\n",
    "                \n",
    "            if query.lower() in ['q', 'quit']:\n",
    "                print(\"\\nğŸ‘‹ ê²€ìƒ‰ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.\")\n",
    "                break\n",
    "                \n",
    "            if query.lower().startswith('mode '):\n",
    "                mode = query.split()[1].lower()\n",
    "                if mode in ['semantic', 'keyword', 'hybrid']:\n",
    "                    search_mode = mode\n",
    "                    print(f\"\\nâœ… ê²€ìƒ‰ ëª¨ë“œë¥¼ '{mode}'ë¡œ ë³€ê²½í–ˆìŠµë‹ˆë‹¤.\")\n",
    "                else:\n",
    "                    print(\"\\nâŒ ì˜ëª»ëœ ê²€ìƒ‰ ëª¨ë“œì…ë‹ˆë‹¤. semantic/keyword/hybrid ì¤‘ ì„ íƒí•˜ì„¸ìš”.\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                print(f\"\\n'{query}' ê²€ìƒ‰ì„ ì‹œì‘í•©ë‹ˆë‹¤... (ëª¨ë“œ: {search_mode})\")\n",
    "                \n",
    "                if search_mode == \"hybrid\":\n",
    "                    results = self.rag.hybrid_search(query, k=k, semantic_weight=0.5)\n",
    "                elif search_mode == \"semantic\":\n",
    "                    results = self.rag.vector_store.similarity_search_with_score(query, k=k)\n",
    "                else:  # keyword\n",
    "                    results = self.rag.keyword_search(query, k=k)\n",
    "                \n",
    "                print(f\"\\nâœ¨ ê²€ìƒ‰ ì™„ë£Œ! {len(results)}ê°œì˜ ê²°ê³¼ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.\\n\")\n",
    "                \n",
    "                # ê²°ê³¼ ì¶œë ¥\n",
    "                for i, (doc, score) in enumerate(results, 1):\n",
    "                    print(f\"\\n{'='*80}\")\n",
    "                    print(f\"ê²€ìƒ‰ ê²°ê³¼ {i}/{len(results)}\")\n",
    "                    print(f\"ì œëª©: {doc.metadata['title']}\")\n",
    "                    print(f\"ë‚ ì§œ: {doc.metadata['date']}\")\n",
    "                    if search_mode == \"hybrid\":\n",
    "                        print(f\"í†µí•© ì ìˆ˜: {score:.4f}\")\n",
    "                    elif search_mode == \"semantic\":\n",
    "                        print(f\"ìœ ì‚¬ë„ ì ìˆ˜: {1 - (score/2):.4f}\")\n",
    "                    else:\n",
    "                        print(f\"BM25 ì ìˆ˜: {score:.4f}\")\n",
    "                    print(f\"URL: {doc.metadata['url']}\")\n",
    "                    print(f\"{'-'*40}\")\n",
    "                    print(f\"ë‚´ìš©:\\n{doc.page_content[:300]}...\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"\\nâŒ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}\")\n",
    "    \n",
    "    @tool\n",
    "    def search_youtube(self, query, max_results=5):\n",
    "        \"\"\"\n",
    "        YouTube APIë¥¼ ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰.\n",
    "        \"\"\"\n",
    "        youtube = googleapiclient.discovery.build(\n",
    "            \"youtube\", \"v3\", developerKey=self.youtube_api_key\n",
    "        )\n",
    "\n",
    "        request = youtube.search().list(\n",
    "            part=\"snippet\",\n",
    "            q=query,\n",
    "            type=\"video\",\n",
    "            maxResults=max_results\n",
    "        )\n",
    "        response = request.execute()\n",
    "\n",
    "        results = [\n",
    "            {\n",
    "                \"title\": item[\"snippet\"][\"title\"],\n",
    "                \"description\": item[\"snippet\"][\"description\"],\n",
    "                \"video_id\": item[\"id\"][\"videoId\"]\n",
    "            }\n",
    "            for item in response.get(\"items\", [])\n",
    "        ]\n",
    "        \n",
    "        for result in results:\n",
    "            print(f\"### {result['title']}\")\n",
    "            video_url = f\"https://www.youtube.com/watch?v={result['video_id']}\"\n",
    "            print(video_url)\n",
    "    \n",
    "    tools = [search_news, search_video]\n",
    "    def analyze_query(self, user_query):\n",
    "        \"\"\"\n",
    "        LLMì„ ì‚¬ìš©í•˜ì—¬ ìœ ì € ì¿¼ë¦¬ë¥¼ ë¶„ì„í•˜ê³  ê·¸ ê²°ê³¼ë¥¼ ë°˜í™˜.\n",
    "        \"\"\"\n",
    "        llm = ChatOpenAI(\n",
    "            model=self.llm_model,\n",
    "            temperature=0.1,\n",
    "            api_key=self.openai_api_key,\n",
    "        )\n",
    "        \n",
    "        self.output_parser = PydanticOutputParser(\n",
    "            pydantic_object=SearchResult\n",
    "        )\n",
    "        \n",
    "        self.prompt = PromptTemplate(\n",
    "            input_variables=[\"user_query\"],\n",
    "            partial_variables={\n",
    "                \"format_instructions\": self.output_parser.get_format_instructions()\n",
    "            },\n",
    "            template=\n",
    "            \"\"\"\n",
    "            ë‹¹ì‹ ì€ AI ê´€ë ¨ ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” ë„ìš°ë¯¸ì…ë‹ˆë‹¤.\n",
    "            ë¨¼ì € ì…ë ¥ëœ ì§ˆì˜ê°€ AI ê´€ë ¨ ë‚´ìš©ì¸ì§€ í™•ì¸í•˜ì„¸ìš”.\n",
    "\n",
    "            AI ê´€ë ¨ ì£¼ì œ íŒë‹¨ ê¸°ì¤€:\n",
    "            - AI ê¸°ìˆ  (ë¨¸ì‹ ëŸ¬ë‹, ë”¥ëŸ¬ë‹, ìì—°ì–´ì²˜ë¦¬ ë“±)\n",
    "            - AI ë„êµ¬ ë° ì„œë¹„ìŠ¤ (ChatGPT, DALL-E, Stable Diffusion ë“±)\n",
    "            - AI íšŒì‚¬ ë° ì—°êµ¬ì†Œ ì†Œì‹\n",
    "            - AI ì •ì±… ë° ê·œì œ\n",
    "            - AI êµìœ¡ ë° í•™ìŠµ\n",
    "            - AI ìœ¤ë¦¬ ë° ì˜í–¥\n",
    "\n",
    "            AI ê´€ë ¨ ì§ˆì˜ê°€ ì•„ë‹Œ ê²½ìš°:\n",
    "            - actionì„ \"not_supported\"ë¡œ ì„¤ì •\n",
    "            - search_keywordëŠ” ë¹ˆ ë¬¸ìì—´ë¡œ ì„¤ì •            \n",
    "\n",
    "            AI ê´€ë ¨ ì§ˆì˜ì¸ ê²½ìš° ë‹¤ìŒ ì‘ì—…ì„ ìˆ˜í–‰í•˜ì„¸ìš”:\n",
    "            1. ê²€ìƒ‰ ë„êµ¬ ì„ ì •: ì§ˆì˜ ì˜ë„ ë¶„ì„ ê¸°ë°˜ ìµœì  ë„êµ¬ ì„ íƒ\n",
    "            2. í‚¤ì›Œë“œ ì¶”ì¶œ: ìµœì í™” ê²€ìƒ‰ì–´ ìƒì„±\n",
    "\n",
    "            ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬:\n",
    "            1. search_video: AI ê´€ë ¨ ì˜ìƒ ì½˜í…ì¸  ê²€ìƒ‰ íŠ¹í™”\n",
    "            2. search_news: AI ê´€ë ¨ ë‰´ìŠ¤ ë° ê¸°ì‚¬ ê²€ìƒ‰ íŠ¹í™”\n",
    "\n",
    "            ë„êµ¬ ì„ íƒ ê¸°ì¤€:\n",
    "            A) search_video ì„ ì • ì¡°ê±´:\n",
    "            - ì˜ìƒ ì½˜í…ì¸  ìš”êµ¬ (ì˜ìƒ, ë™ì˜ìƒ)\n",
    "            - êµìœ¡ ìë£Œ ìš”ì²­ (ê°•ì˜, ê°•ì¢Œ, ìˆ˜ì—…)\n",
    "            - ì‹¤ìŠµ ê°€ì´ë“œ (íŠœí† ë¦¬ì–¼, ê°€ì´ë“œ, ì„¤ëª…)\n",
    "            - ì‹œê°ì  ì„¤ëª… (ì‹œì—°, ë°ëª¨)\n",
    "\n",
    "            B) search_news ì„ ì • ì¡°ê±´:\n",
    "            - ë‰´ìŠ¤ ì½˜í…ì¸  (ë‰´ìŠ¤, ì†Œì‹)\n",
    "            - ê¸°ì‚¬ ìš”ì²­ (ê¸°ì‚¬, ê¸€)\n",
    "            - ì •ë³´ íƒìƒ‰ (ì •ë³´, í˜„í™©, ë™í–¥)\n",
    "            - ì—°êµ¬ ìë£Œ (ì—°êµ¬, ì¡°ì‚¬, ë¶„ì„)\n",
    "\n",
    "            í‚¤ì›Œë“œ ì¶”ì¶œ ê·œì¹™:\n",
    "            1. í•µì‹¬ ì£¼ì œì–´ ë¶„ë¦¬\n",
    "            - AI ê´€ë ¨ í•µì‹¬ ê°œë… ì¶”ì¶œ\n",
    "            - ë§¤ì²´ ìœ í˜• ì§€ì‹œì–´ ì œê±° (ì •ë³´, ë‰´ìŠ¤, ì˜ìƒ, ê¸°ì‚¬ ë“±)\n",
    "            - ë³´ì¡°ì–´ ë° ì¡°ì‚¬ ì œê±°\n",
    "\n",
    "            2. ì˜ë¯¸ë¡ ì  ìµœì í™”\n",
    "            - ì „ë¬¸ ìš©ì–´ ì™„ì „ì„± ìœ ì§€\n",
    "            - ê°œë… ê°„ ê´€ê³„ì„± ë³´ì¡´\n",
    "            - ë§¥ë½ ì í•©ì„± í™•ë³´\n",
    "\n",
    "            ë¶„ì„ ëŒ€ìƒ ì§ˆì˜: {user_query}\n",
    "\n",
    "            {format_instructions}\n",
    "            \"\"\",\n",
    "        )\n",
    "\n",
    "        # ì‹¤í–‰ ì²´ì¸ ìƒì„± - í”„ë¡¬í”„íŠ¸ ì²˜ë¦¬ë¶€í„° ê²°ê³¼ íŒŒì‹±ê¹Œì§€ì˜ ì „ì²´ íë¦„\n",
    "        self.chain = RunnableSequence(\n",
    "            first= {\"user_query\": RunnablePassthrough()} | self.prompt,  # ë¨¼ì € í”„ë¡¬í”„íŠ¸ ì²˜ë¦¬\n",
    "            middle=[llm.bind_tools(tools)],  # ê·¸ ë‹¤ìŒ LLMìœ¼ë¡œ ì²˜ë¦¬\n",
    "            last=self.output_parser,  # ë§ˆì§€ë§‰ìœ¼ë¡œ ê²°ê³¼ íŒŒì‹±\n",
    "        )\n",
    "        \n",
    "        print('here')\n",
    "        response = self.chain.invoke(user_query)  # ì§ˆë¬¸ ë¶„ì„\n",
    "        print(response.tool_calls)\n",
    "        \n",
    "        return response.model_dump()  # json í˜•ì‹ìœ¼ë¡œ ë³€í˜•í˜•\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Search Agent\n",
      "==============================\n",
      "LLMì„ í†µí•´ ì…ë ¥ ì¿¼ë¦¬ë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤...\n",
      "Error occurred: Cannot generate a JsonSchema for core_schema.IsInstanceSchema (<class 'Keyword_Hybrid_RAG.AINewsRAG'>)\n",
      "\n",
      "For further information visit https://errors.pydantic.dev/2.10/u/invalid-for-json-schema\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    try:\n",
    "        load_dotenv()\n",
    "        \n",
    "        # í™˜ê²½ ë³€ìˆ˜ì—ì„œ OpenAI API í‚¤ë¥¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "        openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "        if not openai_api_key:\n",
    "            print(\"OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.\")\n",
    "            return\n",
    "        \n",
    "        # í™˜ê²½ ë³€ìˆ˜ì—ì„œ YouTube API í‚¤ë¥¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "        youtube_api_key = os.getenv(\"YOUTUBE_API_KEY\")\n",
    "        if not youtube_api_key:\n",
    "            print(\"YOUTUBE_API_KEY í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.\")\n",
    "            return\n",
    "\n",
    "        # ìœ ì € ì…ë ¥ ë°›ê¸°\n",
    "        print(\"AI Search Agent\")\n",
    "        user_query = input(\"ê²€ìƒ‰í•  ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: AI ë‰´ìŠ¤ ê´€ë ¨ ì˜ìƒì„ ì•Œë ¤ì¤˜):\")\n",
    "\n",
    "        if user_query:\n",
    "            # Agent ì´ˆê¸°í™”\n",
    "            agent = SearchAgent(openai_api_key, youtube_api_key)\n",
    "            \n",
    "            # ì¿¼ë¦¬ ë¶„ì„\n",
    "            print(\"=\"*30)\n",
    "            print(\"LLMì„ í†µí•´ ì…ë ¥ ì¿¼ë¦¬ë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤...\")\n",
    "            result = agent.analyze_query(user_query)\n",
    "            print(f\"ê²€ìƒ‰ ê²°ê³¼: {result}\")\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Shutting down process...\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SearchAgent:\n",
    "    def __init__(self, openai_api_key, youtube_api_key, llm_model=\"gpt-4o\"):\n",
    "        self.openai_api_key = openai_api_key\n",
    "        self.youtube_api_key = youtube_api_key\n",
    "        self.llm_model = llm_model\n",
    "    \n",
    "    def analyze_query(self, user_query):\n",
    "        \"\"\"\n",
    "        LLMì„ ì‚¬ìš©í•˜ì—¬ ìœ ì € ì¿¼ë¦¬ë¥¼ ë¶„ì„í•˜ê³  ê·¸ ê²°ê³¼ë¥¼ ë°˜í™˜.\n",
    "        \"\"\"\n",
    "        llm = ChatOpenAI(\n",
    "            model=self.llm_model,\n",
    "            temperature=0.1,\n",
    "            api_key=self.openai_api_key,\n",
    "        )\n",
    "        \n",
    "        self.output_parser = PydanticOutputParser(\n",
    "            pydantic_object=SearchResult\n",
    "        )\n",
    "        \n",
    "        self.prompt = PromptTemplate(\n",
    "            input_variables=[\"user_query\"],\n",
    "            partial_variables={\n",
    "                \"format_instructions\": self.output_parser.get_format_instructions()\n",
    "            },\n",
    "            template=\n",
    "            \"\"\"\n",
    "            ë‹¹ì‹ ì€ AI ê´€ë ¨ ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” ë„ìš°ë¯¸ì…ë‹ˆë‹¤.\n",
    "            ë¨¼ì € ì…ë ¥ëœ ì§ˆì˜ê°€ AI ê´€ë ¨ ë‚´ìš©ì¸ì§€ í™•ì¸í•˜ì„¸ìš”.\n",
    "\n",
    "            AI ê´€ë ¨ ì£¼ì œ íŒë‹¨ ê¸°ì¤€:\n",
    "            - AI ê¸°ìˆ  (ë¨¸ì‹ ëŸ¬ë‹, ë”¥ëŸ¬ë‹, ìì—°ì–´ì²˜ë¦¬ ë“±)\n",
    "            - AI ë„êµ¬ ë° ì„œë¹„ìŠ¤ (ChatGPT, DALL-E, Stable Diffusion ë“±)\n",
    "            - AI íšŒì‚¬ ë° ì—°êµ¬ì†Œ ì†Œì‹\n",
    "            - AI ì •ì±… ë° ê·œì œ\n",
    "            - AI êµìœ¡ ë° í•™ìŠµ\n",
    "            - AI ìœ¤ë¦¬ ë° ì˜í–¥\n",
    "\n",
    "            AI ê´€ë ¨ ì§ˆì˜ê°€ ì•„ë‹Œ ê²½ìš°:\n",
    "            - actionì„ \"not_supported\"ë¡œ ì„¤ì •\n",
    "            - search_keywordëŠ” ë¹ˆ ë¬¸ìì—´ë¡œ ì„¤ì •            \n",
    "\n",
    "            AI ê´€ë ¨ ì§ˆì˜ì¸ ê²½ìš° ë‹¤ìŒ ì‘ì—…ì„ ìˆ˜í–‰í•˜ì„¸ìš”:\n",
    "            1. ê²€ìƒ‰ ë„êµ¬ ì„ ì •: ì§ˆì˜ ì˜ë„ ë¶„ì„ ê¸°ë°˜ ìµœì  ë„êµ¬ ì„ íƒ\n",
    "            2. í‚¤ì›Œë“œ ì¶”ì¶œ: ìµœì í™” ê²€ìƒ‰ì–´ ìƒì„±\n",
    "\n",
    "            ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬:\n",
    "            1. search_video: AI ê´€ë ¨ ì˜ìƒ ì½˜í…ì¸  ê²€ìƒ‰ íŠ¹í™”\n",
    "            2. search_news: AI ê´€ë ¨ ë‰´ìŠ¤ ë° ê¸°ì‚¬ ê²€ìƒ‰ íŠ¹í™”\n",
    "\n",
    "            ë„êµ¬ ì„ íƒ ê¸°ì¤€:\n",
    "            A) search_video ì„ ì • ì¡°ê±´:\n",
    "            - ì˜ìƒ ì½˜í…ì¸  ìš”êµ¬ (ì˜ìƒ, ë™ì˜ìƒ)\n",
    "            - êµìœ¡ ìë£Œ ìš”ì²­ (ê°•ì˜, ê°•ì¢Œ, ìˆ˜ì—…)\n",
    "            - ì‹¤ìŠµ ê°€ì´ë“œ (íŠœí† ë¦¬ì–¼, ê°€ì´ë“œ, ì„¤ëª…)\n",
    "            - ì‹œê°ì  ì„¤ëª… (ì‹œì—°, ë°ëª¨)\n",
    "\n",
    "            B) search_news ì„ ì • ì¡°ê±´:\n",
    "            - ë‰´ìŠ¤ ì½˜í…ì¸  (ë‰´ìŠ¤, ì†Œì‹)\n",
    "            - ê¸°ì‚¬ ìš”ì²­ (ê¸°ì‚¬, ê¸€)\n",
    "            - ì •ë³´ íƒìƒ‰ (ì •ë³´, í˜„í™©, ë™í–¥)\n",
    "            - ì—°êµ¬ ìë£Œ (ì—°êµ¬, ì¡°ì‚¬, ë¶„ì„)\n",
    "\n",
    "            í‚¤ì›Œë“œ ì¶”ì¶œ ê·œì¹™:\n",
    "            1. í•µì‹¬ ì£¼ì œì–´ ë¶„ë¦¬\n",
    "            - AI ê´€ë ¨ í•µì‹¬ ê°œë… ì¶”ì¶œ\n",
    "            - ë§¤ì²´ ìœ í˜• ì§€ì‹œì–´ ì œê±° (ì •ë³´, ë‰´ìŠ¤, ì˜ìƒ, ê¸°ì‚¬ ë“±)\n",
    "            - ë³´ì¡°ì–´ ë° ì¡°ì‚¬ ì œê±°\n",
    "\n",
    "            2. ì˜ë¯¸ë¡ ì  ìµœì í™”\n",
    "            - ì „ë¬¸ ìš©ì–´ ì™„ì „ì„± ìœ ì§€\n",
    "            - ê°œë… ê°„ ê´€ê³„ì„± ë³´ì¡´\n",
    "            - ë§¥ë½ ì í•©ì„± í™•ë³´\n",
    "\n",
    "            ë¶„ì„ ëŒ€ìƒ ì§ˆì˜: {user_query}\n",
    "\n",
    "            {format_instructions}\n",
    "            \"\"\",\n",
    "        )\n",
    "\n",
    "        # ì‹¤í–‰ ì²´ì¸ ìƒì„± - í”„ë¡¬í”„íŠ¸ ì²˜ë¦¬ë¶€í„° ê²°ê³¼ íŒŒì‹±ê¹Œì§€ì˜ ì „ì²´ íë¦„\n",
    "        self.chain = RunnableSequence(\n",
    "            first= {\"user_query\": RunnablePassthrough()} | self.prompt,  # ë¨¼ì € í”„ë¡¬í”„íŠ¸ ì²˜ë¦¬\n",
    "            middle=[llm.bind_tools(tools)],  # ê·¸ ë‹¤ìŒ LLMìœ¼ë¡œ ì²˜ë¦¬\n",
    "            last=self.output_parser,  # ë§ˆì§€ë§‰ìœ¼ë¡œ ê²°ê³¼ íŒŒì‹±\n",
    "        )\n",
    "        \n",
    "        response = self.chain.invoke(user_query)  # ì§ˆë¬¸ ë¶„ì„\n",
    "        print(response)\n",
    "        \n",
    "        return response.model_dump()  # json í˜•ì‹ìœ¼ë¡œ ë³€í˜•í˜•\n",
    "\n",
    "    def search_youtube(self, query, max_results=5):\n",
    "        \"\"\"\n",
    "        YouTube APIë¥¼ ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰.\n",
    "        \"\"\"\n",
    "        youtube = googleapiclient.discovery.build(\n",
    "            \"youtube\", \"v3\", developerKey=self.youtube_api_key\n",
    "        )\n",
    "\n",
    "        request = youtube.search().list(\n",
    "            part=\"snippet\",\n",
    "            q=query,\n",
    "            type=\"video\",\n",
    "            maxResults=max_results\n",
    "        )\n",
    "        response = request.execute()\n",
    "\n",
    "        results = [\n",
    "            {\n",
    "                \"title\": item[\"snippet\"][\"title\"],\n",
    "                \"description\": item[\"snippet\"][\"description\"],\n",
    "                \"video_id\": item[\"id\"][\"videoId\"]\n",
    "            }\n",
    "            for item in response.get(\"items\", [])\n",
    "        ]\n",
    "        return results\n",
    "\n",
    "    def format_results_for_display(self, results):\n",
    "        \"\"\"\n",
    "        ê²€ìƒ‰ ê²°ê³¼ë¥¼ ìŠ¤íŠ¸ë¦¼ë¦¿ì—ì„œ ë³´ì—¬ì¤„ ìˆ˜ ìˆë„ë¡ í¬ë§·íŒ….\n",
    "        \"\"\"\n",
    "        for result in results:\n",
    "            print(f\"### {result['title']}\")\n",
    "            #video_url = f\"https://www.youtube.com/watch?v={result['video_id']}\"\n",
    "            #print(video_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Search Agent\n",
      "==============================\n",
      "LLMì„ í†µí•´ ì…ë ¥ ì¿¼ë¦¬ë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤...\n",
      "Error occurred: Cannot generate a JsonSchema for core_schema.IsInstanceSchema (<class 'Keyword_Hybrid_RAG.AINewsRAG'>)\n",
      "\n",
      "For further information visit https://errors.pydantic.dev/2.10/u/invalid-for-json-schema\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    try:\n",
    "        load_dotenv()\n",
    "        \n",
    "        # í™˜ê²½ ë³€ìˆ˜ì—ì„œ OpenAI API í‚¤ë¥¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "        openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "        if not openai_api_key:\n",
    "            print(\"OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.\")\n",
    "            return\n",
    "        \n",
    "        # í™˜ê²½ ë³€ìˆ˜ì—ì„œ YouTube API í‚¤ë¥¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "        youtube_api_key = os.getenv(\"YOUTUBE_API_KEY\")\n",
    "        if not youtube_api_key:\n",
    "            print(\"YOUTUBE_API_KEY í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.\")\n",
    "            return\n",
    "\n",
    "        # ìœ ì € ì…ë ¥ ë°›ê¸°\n",
    "        print(\"AI Search Agent\")\n",
    "        user_query = input(\"ê²€ìƒ‰í•  ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: AI ë‰´ìŠ¤ ê´€ë ¨ ì˜ìƒì„ ì•Œë ¤ì¤˜):\")\n",
    "\n",
    "        if user_query:\n",
    "            # Agent ì´ˆê¸°í™”\n",
    "            agent = SearchAgent(openai_api_key, youtube_api_key)\n",
    "            \n",
    "            # ì¿¼ë¦¬ ë¶„ì„\n",
    "            print(\"=\"*30)\n",
    "            print(\"LLMì„ í†µí•´ ì…ë ¥ ì¿¼ë¦¬ë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤...\")\n",
    "            result = agent.analyze_query(user_query)\n",
    "            print(f\"ê²€ìƒ‰ ê²°ê³¼: {result}\")\n",
    "\n",
    "            # YouTube ê²€ìƒ‰\n",
    "            print(\"=\"*30)\n",
    "            print(\"YouTubeì—ì„œ ê²€ìƒ‰ ì¤‘ì…ë‹ˆë‹¤...\")\n",
    "            search_results = agent.search_youtube(result['search_keywords'])\n",
    "\n",
    "            # ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ\n",
    "            if search_results:\n",
    "                print(\"ê²€ìƒ‰ ê²°ê³¼:\")\n",
    "                agent.format_results_for_display(search_results)\n",
    "            else:\n",
    "                print(\"ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "            \n",
    "            # ë‰´ìŠ¤ ê²€ìƒ‰\n",
    "            print(\"=\"*30)\n",
    "            print(\"ë‰´ìŠ¤ìŠ¤ì—ì„œ ê²€ìƒ‰ ì¤‘ì…ë‹ˆë‹¤...\")\n",
    "            search_results = agent.search_new(result['search_keywords'])\n",
    "\n",
    "            # ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ\n",
    "            if search_results:\n",
    "                print(\"ê²€ìƒ‰ ê²°ê³¼:\")\n",
    "                agent.format_results_for_display(search_results)\n",
    "            else:\n",
    "                print(\"ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Shutting down process...\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG_Agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
