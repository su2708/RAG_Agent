{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2단계:**\n",
    "\n",
    "- 유투브 AI 내용 검색 Agent 추가\n",
    "    - 유투브 API 활용\n",
    "    - 예시 입력 프롬프트 : AI 뉴스관련 영상을 알려줘\n",
    "    - Agent를 통해서 유투브 API를 통해 뉴스 검색 후 검색 된 내용을 프롬프트에 넣어서 알려주기\n",
    "        - streamlit 유투브 영상 화면 까지 같이 보여주기 (재생할 수 있는)\n",
    "    - Agent는 유저의 쿼리를 LLM이 분석해서 특정 함수를 실행\n",
    "    - **공식문서 참고해서 Agent내용 학습후 코드화 (베스트)**\n",
    "        - Quick Start (가이드 코드)\n",
    "        - Lanchain : 안배웠다하더라도 스스로 찾아서 할 수 있어야한다.\n",
    "        - App\n",
    "\n",
    "### 아이디어 정리\n",
    "1. 사용자의 질문 입력\n",
    "2. 질문을 LLM으로 보내 검색 키워드 분석\n",
    "3. 검색 키워드에 맞는 tool 설정\n",
    "4. tool 동작 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import googleapiclient.discovery\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableSequence\n",
    "from langchain.agents import Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "새로운 벡터 스토어를 생성합니다...\n",
      "2024-12-17 09:32:32,491 - 총 0개의 JSON 파일을 로드합니다...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "JSON 파일 로드 중: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-17 09:32:32,495 - 총 0개의 뉴스 기사를 로드했습니다.\n",
      "2024-12-17 09:32:32,496 - 문서 처리 및 청크 분할을 시작합니다...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "문서 처리 중: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-17 09:32:32,500 - BM25 검색 엔진을 초기화합니다...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# import sys\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# sys.path.append(\"C:/Users/USER/anaconda3/envs/SpartaProjects/Personal_Project/RAG_Agent/RAG_Agent\")\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mKeyword_Hybrid_RAG\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AINewsRAG\n",
      "File \u001b[1;32mC:\\Users/USER/anaconda3/envs/SpartaProjects/Personal_Project/RAG_Agent/RAG_Agent\\Keyword_Hybrid_RAG.py:390\u001b[0m\n\u001b[0;32m    387\u001b[0m documents \u001b[38;5;241m=\u001b[39m rag\u001b[38;5;241m.\u001b[39mload_json_files(news_dir)\n\u001b[0;32m    389\u001b[0m \u001b[38;5;66;03m# 문서 처리 및 벡터 스토어 생성\u001b[39;00m\n\u001b[1;32m--> 390\u001b[0m processed_docs \u001b[38;5;241m=\u001b[39m \u001b[43mrag\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    391\u001b[0m rag\u001b[38;5;241m.\u001b[39mcreate_vector_store(processed_docs)\n\u001b[0;32m    393\u001b[0m \u001b[38;5;66;03m# 벡터 스토어 저장\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Users/USER/anaconda3/envs/SpartaProjects/Personal_Project/RAG_Agent/RAG_Agent\\Keyword_Hybrid_RAG.py:172\u001b[0m, in \u001b[0;36mAINewsRAG.process_documents\u001b[1;34m(self, documents)\u001b[0m\n\u001b[0;32m    169\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m문서 처리 중 오류 발생: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdoc\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnknown\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessed_docs \u001b[38;5;241m=\u001b[39m processed_docs\n\u001b[1;32m--> 172\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitialize_bm25\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocessed_docs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m processed_docs\n",
      "File \u001b[1;32mC:\\Users/USER/anaconda3/envs/SpartaProjects/Personal_Project/RAG_Agent/RAG_Agent\\Keyword_Hybrid_RAG.py:190\u001b[0m, in \u001b[0;36mAINewsRAG.initialize_bm25\u001b[1;34m(self, documents)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBM25 검색 엔진을 초기화합니다...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    185\u001b[0m tokenized_corpus \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    186\u001b[0m     doc\u001b[38;5;241m.\u001b[39mpage_content\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39msplit() \n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents\n\u001b[0;32m    188\u001b[0m ]\n\u001b[1;32m--> 190\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbm25 \u001b[38;5;241m=\u001b[39m \u001b[43mBM25Okapi\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenized_corpus\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdoc_mapping \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    192\u001b[0m     i: doc \u001b[38;5;28;01mfor\u001b[39;00m i, doc \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(documents)\n\u001b[0;32m    193\u001b[0m }\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBM25 검색 엔진 초기화가 완료되었습니다.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\SpartaProjects\\Personal_Project\\RAG_Agent\\Lib\\site-packages\\rank_bm25.py:83\u001b[0m, in \u001b[0;36mBM25Okapi.__init__\u001b[1;34m(self, corpus, tokenizer, k1, b, epsilon)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb \u001b[38;5;241m=\u001b[39m b\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepsilon \u001b[38;5;241m=\u001b[39m epsilon\n\u001b[1;32m---> 83\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcorpus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\SpartaProjects\\Personal_Project\\RAG_Agent\\Lib\\site-packages\\rank_bm25.py:27\u001b[0m, in \u001b[0;36mBM25.__init__\u001b[1;34m(self, corpus, tokenizer)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tokenizer:\n\u001b[0;32m     25\u001b[0m     corpus \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tokenize_corpus(corpus)\n\u001b[1;32m---> 27\u001b[0m nd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcorpus\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_calc_idf(nd)\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\SpartaProjects\\Personal_Project\\RAG_Agent\\Lib\\site-packages\\rank_bm25.py:52\u001b[0m, in \u001b[0;36mBM25._initialize\u001b[1;34m(self, corpus)\u001b[0m\n\u001b[0;32m     48\u001b[0m             nd[word] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcorpus_size \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 52\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavgdl \u001b[38;5;241m=\u001b[39m \u001b[43mnum_doc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorpus_size\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m nd\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"C:/Users/USER/anaconda3/envs/SpartaProjects/Personal_Project/RAG_Agent/RAG_Agent\")\n",
    "\n",
    "from Keyword_Hybrid_RAG import AINewsRAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-13 01:35:33,121 - 데이터를 ai_news_vectorstore에서 로드합니다...\n",
      "2024-12-13 01:35:37,261 - BM25 검색 엔진을 초기화합니다...\n",
      "2024-12-13 01:35:42,559 - BM25 검색 엔진 초기화가 완료되었습니다.\n",
      "2024-12-13 01:35:42,639 - 로드가 완료되었습니다.\n",
      "✅ 기존 벡터 스토어를 로드했습니다.\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "\n",
    "# 환경 변수에서 경로 가져오기\n",
    "vector_store_path = os.getenv(\"VECTOR_STORE_NAME\", \"ai_news_vectorstore\")\n",
    "news_dir = os.getenv(\"NEWS_FILE_PATH\", \"./ai_news\")\n",
    "processed_doc_path = os.getenv(\"PROCESSED_DOCS_PATH\", \"processed_docs/processed_docs.pkl\")\n",
    "\n",
    "# 임베딩 모델 초기화 \n",
    "embedding_model = OpenAIEmbeddings(\n",
    "    model=os.getenv(\"OPENAI_EMBEDDING_MODEL\", \"text-embedding-3-small\")\n",
    ")\n",
    "\n",
    "# 환경 변수에서 OpenAI API 키를 불러오기\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not openai_api_key:\n",
    "    print(\"OPENAI_API_KEY 환경 변수를 설정해주세요.\")\n",
    "\n",
    "# 환경 변수에서 YouTube API 키를 불러오기\n",
    "youtube_api_key = os.getenv(\"YOUTUBE_API_KEY\")\n",
    "if not youtube_api_key:\n",
    "    print(\"YOUTUBE_API_KEY 환경 변수를 설정해주세요.\")\n",
    "\n",
    "# RAG 시스템 초기화\n",
    "rag = AINewsRAG(embedding_model)\n",
    "\n",
    "try:\n",
    "    # 기존 벡터 스토어 로드 시도\n",
    "    rag.load_vector_store(vector_store_path, processed_doc_path)\n",
    "    print(\"✅ 기존 벡터 스토어를 로드했습니다.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"벡터 스토어 로드 실패: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def search_news(query: str, k: int = 5):\n",
    "    \"\"\"\n",
    "    하이브리드 검색 방식으로 AI 뉴스를 검색합니다.\n",
    "    \"\"\"\n",
    "    search_mode = \"hybrid\" # 검색 방식 변경은 'mode [semantic/keyword/hybrid]'를 입력하세요.\n",
    "    while True:\n",
    "        query = query.strip()\n",
    "\n",
    "        if not query:\n",
    "            continue\n",
    "            \n",
    "        if query.lower() in ['q', 'quit']:\n",
    "            print(\"\\n👋 검색을 종료합니다.\")\n",
    "            break\n",
    "            \n",
    "        if query.lower().startswith('mode '):\n",
    "            mode = query.split()[1].lower()\n",
    "            if mode in ['semantic', 'keyword', 'hybrid']:\n",
    "                search_mode = mode\n",
    "                print(f\"\\n✅ 검색 모드를 '{mode}'로 변경했습니다.\")\n",
    "            else:\n",
    "                print(\"\\n❌ 잘못된 검색 모드입니다. semantic/keyword/hybrid 중 선택하세요.\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            print(f\"\\n'{query}' 검색을 시작합니다... (모드: {search_mode})\")\n",
    "            \n",
    "            if search_mode == \"hybrid\":\n",
    "                results = rag.hybrid_search(query, k=k, semantic_weight=0.5)\n",
    "            elif search_mode == \"semantic\":\n",
    "                results = rag.vector_store.similarity_search_with_score(query, k=k)\n",
    "            else:  # keyword\n",
    "                results = rag.keyword_search(query, k=k)\n",
    "            \n",
    "            print(f\"\\n✨ 검색 완료! {len(results)}개의 결과를 찾았습니다.\\n\")\n",
    "            \n",
    "            # 결과 출력\n",
    "            for i, (doc, score) in enumerate(results, 1):\n",
    "                print(f\"\\n{'='*80}\")\n",
    "                print(f\"검색 결과 {i}/{len(results)}\")\n",
    "                print(f\"제목: {doc.metadata['title']}\")\n",
    "                print(f\"날짜: {doc.metadata['date']}\")\n",
    "                if search_mode == \"hybrid\":\n",
    "                    print(f\"통합 점수: {score:.4f}\")\n",
    "                elif search_mode == \"semantic\":\n",
    "                    print(f\"유사도 점수: {1 - (score/2):.4f}\")\n",
    "                else:\n",
    "                    print(f\"BM25 점수: {score:.4f}\")\n",
    "                print(f\"URL: {doc.metadata['url']}\")\n",
    "                print(f\"{'-'*40}\")\n",
    "                print(f\"내용:\\n{doc.page_content[:300]}...\")\n",
    "            \n",
    "            # 종료\n",
    "            break\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"\\n❌ 검색 중 오류가 발생했습니다: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def search_video(query, max_results=5):\n",
    "        \"\"\"\n",
    "        YouTube API를 사용하여 검색.\n",
    "        \"\"\"\n",
    "        youtube = googleapiclient.discovery.build(\n",
    "            \"youtube\", \"v3\", developerKey=youtube_api_key\n",
    "        )\n",
    "\n",
    "        request = youtube.search().list(\n",
    "            part=\"snippet\",\n",
    "            q=query,\n",
    "            type=\"video\",\n",
    "            maxResults=max_results\n",
    "        )\n",
    "        response = request.execute()\n",
    "\n",
    "        results = [\n",
    "            {\n",
    "                \"title\": item[\"snippet\"][\"title\"],\n",
    "                \"description\": item[\"snippet\"][\"description\"],\n",
    "                \"video_id\": item[\"id\"][\"videoId\"]\n",
    "            }\n",
    "            for item in response.get(\"items\", [])\n",
    "        ]\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Search youtube tool\",\n",
    "        func=search_video,\n",
    "        description=\"YouTube API를 사용하여 검색합니다.\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Search news tool\",\n",
    "        func=search_news,\n",
    "        description=\"하이브리드 검색 방식으로 AI 뉴스를 검색합니다.\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SearchResult(BaseModel):\n",
    "    \"\"\"\n",
    "    사용자 질문: str\n",
    "    액션: str\n",
    "    검색 키워드: str\n",
    "    tool 설정: str\n",
    "    \"\"\"\n",
    "    user_query: str\n",
    "    action: str\n",
    "    search_keywords: str\n",
    "    tool: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AIAgent:\n",
    "    def __init__(self, openai_api_key, youtube_api_key, llm_model=\"gpt-4o\"):\n",
    "        self.openai_api_key = openai_api_key\n",
    "        self.youtube_api_key = youtube_api_key\n",
    "        self.llm_model = llm_model\n",
    "    \n",
    "    def analyze_query(self, user_query):\n",
    "        \"\"\"\n",
    "        LLM을 사용하여 유저 쿼리를 분석하고 그 결과를 반환.\n",
    "        \"\"\"\n",
    "        llm = ChatOpenAI(\n",
    "            model=self.llm_model,\n",
    "            temperature=0.1,\n",
    "            api_key=self.openai_api_key,\n",
    "        )\n",
    "        \n",
    "        self.output_parser = PydanticOutputParser(\n",
    "            pydantic_object=SearchResult\n",
    "        )\n",
    "        \n",
    "        self.prompt = PromptTemplate(\n",
    "            input_variables=[\"user_query\"],\n",
    "            partial_variables={\n",
    "                \"format_instructions\": self.output_parser.get_format_instructions()\n",
    "            },\n",
    "            template=\n",
    "            \"\"\"\n",
    "            당신은 AI 관련 정보를 제공하는 도우미입니다.\n",
    "            먼저 입력된 질의가 AI 관련 내용인지 확인하세요.\n",
    "\n",
    "            AI 관련 주제 판단 기준:\n",
    "            - AI 기술 (머신러닝, 딥러닝, 자연어처리 등)\n",
    "            - AI 도구 및 서비스 (ChatGPT, DALL-E, Stable Diffusion 등)\n",
    "            - AI 회사 및 연구소 소식\n",
    "            - AI 정책 및 규제\n",
    "            - AI 교육 및 학습\n",
    "            - AI 윤리 및 영향\n",
    "\n",
    "            AI 관련 질의가 아닌 경우:\n",
    "            - action을 \"not_supported\"로 설정\n",
    "            - search_keyword는 빈 문자열로 설정            \n",
    "\n",
    "            AI 관련 질의인 경우 다음 작업을 수행하세요:\n",
    "            1. 검색 도구 선정: 질의 의도 분석 기반 최적 도구 선택\n",
    "            2. 키워드 추출: 최적화 검색어 생성\n",
    "\n",
    "            사용 가능한 도구:\n",
    "            1. search_video: AI 관련 영상 콘텐츠 검색 특화\n",
    "            2. search_news: AI 관련 뉴스 및 기사 검색 특화\n",
    "\n",
    "            도구 선택 기준:\n",
    "            A) search_video 선정 조건:\n",
    "            - 영상 콘텐츠 요구 (영상, 동영상)\n",
    "            - 교육 자료 요청 (강의, 강좌, 수업)\n",
    "            - 실습 가이드 (튜토리얼, 가이드, 설명)\n",
    "            - 시각적 설명 (시연, 데모)\n",
    "\n",
    "            B) search_news 선정 조건:\n",
    "            - 뉴스 콘텐츠 (뉴스, 소식)\n",
    "            - 기사 요청 (기사, 글)\n",
    "            - 정보 탐색 (정보, 현황, 동향)\n",
    "            - 연구 자료 (연구, 조사, 분석)\n",
    "\n",
    "            키워드 추출 규칙:\n",
    "            1. 핵심 주제어 분리\n",
    "            - AI 관련 핵심 개념 추출\n",
    "            - 매체 유형 지시어 제거 (정보, 뉴스, 영상, 기사 등)\n",
    "            - 보조어 및 조사 제거\n",
    "\n",
    "            2. 의미론적 최적화\n",
    "            - 전문 용어 완전성 유지\n",
    "            - 개념 간 관계성 보존\n",
    "            - 맥락 적합성 확보\n",
    "\n",
    "            분석 대상 질의: {user_query}\n",
    "\n",
    "            {format_instructions}\n",
    "            \"\"\",\n",
    "        )\n",
    "\n",
    "        # 실행 체인 생성 - 프롬프트 처리부터 결과 파싱까지의 전체 흐름\n",
    "        self.chain = RunnableSequence(\n",
    "            first= {\"user_query\": RunnablePassthrough()} | self.prompt,  # 먼저 프롬프트 처리\n",
    "            middle=[llm],  # 그 다음 LLM으로 처리\n",
    "            last=self.output_parser,  # 마지막으로 결과 파싱\n",
    "        )\n",
    "        \n",
    "        response = self.chain.invoke(user_query)  # 질문 분석\n",
    "        print(response)\n",
    "        \n",
    "        return response.model_dump()  # json 형식으로 변형형\n",
    "\n",
    "    def format_results_for_display(self, results):\n",
    "        \"\"\"\n",
    "        검색 결과를 스트림릿에서 보여줄 수 있도록 포맷팅.\n",
    "        \"\"\"\n",
    "        for result in results:\n",
    "            print(f\"### {result['title']}\")\n",
    "            if result['video_id']:\n",
    "                video_url = f\"https://www.youtube.com/watch?v={result['video_id']}\"\n",
    "                print(video_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Search Agent\n",
      "==============================\n",
      "LLM을 통해 입력 쿼리를 분석 중입니다...\n",
      "user_query='AI 구조에 대한 영상 추천해줘' action='search' search_keywords='AI 구조' tool='search_video'\n",
      "검색 결과: {'user_query': 'AI 구조에 대한 영상 추천해줘', 'action': 'search', 'search_keywords': 'AI 구조', 'tool': 'search_video'}\n",
      "==============================\n",
      "YouTube에서 검색 중입니다...\n",
      "검색 결과:\n",
      "### AI의 기초 원리부터 최신 알고리즘까지! AI 전문가가 되기 위한 모든 과정 한방 정리!\n",
      "https://www.youtube.com/watch?v=qj4QOcW-vpg\n",
      "### 인공지능(AI)의 원리에 대해 알아보자!\n",
      "https://www.youtube.com/watch?v=s1Qz55ZTxWQ\n",
      "### AI한테 한국 x진을 그려 달라했다\n",
      "https://www.youtube.com/watch?v=_tPvKDqNokE\n",
      "### [자막뉴스] &#39;소름 쫙&#39; AI에 대해 질문했더니...로봇의 섬뜩한 답변 / YTN\n",
      "https://www.youtube.com/watch?v=lfbict0xXxc\n",
      "### 단백질 구조를 예측하는 AI?! 2024 노벨 화학상\n",
      "https://www.youtube.com/watch?v=W8KS78GSzio\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    try:\n",
    "        # 유저 입력 받기\n",
    "        print(\"AI Search Agent\")\n",
    "        user_query = input(\"검색할 내용을 입력하세요 (예: AI 뉴스 관련 영상을 알려줘):\")\n",
    "\n",
    "        if user_query:\n",
    "            # Agent 초기화\n",
    "            agent = AIAgent(openai_api_key, youtube_api_key)\n",
    "            \n",
    "            # 쿼리 분석\n",
    "            print(\"=\"*30)\n",
    "            print(\"LLM을 통해 입력 쿼리를 분석 중입니다...\")\n",
    "            result = agent.analyze_query(user_query)\n",
    "            print(f\"검색 결과: {result}\")\n",
    "            \n",
    "            # tool에 따른 동작 실행 \n",
    "            tool_names = [tool.func.name for tool in tools]  # tool 이름 받기 \n",
    "            if result['tool'] in tool_names:\n",
    "                # YouTube 검색\n",
    "                if result['tool'] == 'search_video':\n",
    "                    print(\"=\"*30)\n",
    "                    print(\"YouTube에서 검색 중입니다...\")\n",
    "                    search_results = search_video(result['search_keywords'])\n",
    "\n",
    "                    # 검색 결과 표시\n",
    "                    if search_results:\n",
    "                        print(\"검색 결과:\")\n",
    "                        agent.format_results_for_display(search_results)\n",
    "                    else:\n",
    "                        print(\"검색 결과가 없습니다.\")\n",
    "            \n",
    "                # 뉴스 검색\n",
    "                else:\n",
    "                    print(\"=\"*30)\n",
    "                    print(\"뉴스에서 검색 중입니다...\")\n",
    "                    search_results = search_news(result['search_keywords'])\n",
    "\n",
    "                    # 검색 결과 표시\n",
    "                    if search_results:\n",
    "                        print(\"검색 결과:\")\n",
    "                        agent.format_results_for_display(search_results)\n",
    "                    else:\n",
    "                        print(\"검색 결과가 없습니다.\")\n",
    "            \n",
    "            else:\n",
    "                print(\"AI와 관련된 질문만 받을 수 있습니다.\")\n",
    "            \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Shutting down process...\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG_Agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
